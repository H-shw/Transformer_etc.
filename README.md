# 介绍与进度

本仓库用于存储学习进度。应当在完工的时候会包括 

* transformer论文阅读
* transformer 复现
* BERT 论文阅读
* Huggingface 里的  Transformers,  fairseq 的知识等。

有空的话欢迎 check 进度，告知可以改进的方面(比如代码风格等)。



## 进度

这里会用很简短的语言描述今天做了什么(也可能包含不只是关于本次学习的内容)，不过如果今天摸鱼了也会写上来。。



* **2022.5.17**

获得材料，开始阅读 Attention is all you need(http://papers.neurips.cc/paper/7181-attention-is-all-you-need.pdf)。



* **2022.5.18**

今天比较空闲，就多花了时间在这上面。

早上大概把论文看完了，然后阅读了一篇质量不错的博客辅助理解(https://luweikxy.gitbook.io/machine-learning-notes/self-attention-and-transformer)。一个非常初期的报告点击这里。

下午开始看代码，着手复现 *Transformer* 。

晚上感觉差不多把 *Transformer* 模型大概搭好了？应该说 *Transformer* 代码量并不大，不过感觉参考别人的思路多了些。。不过有些细节按照自己的想法写了，也许有 *bug* , 后面还需要检查。

明天课比较多，还打算学学因果推理 ( *causal inference* ) 的东西，周五组会。









 

