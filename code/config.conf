[model]
model_name = Transformer
N = 8
d_k = 64
d_v = 64
d_model = 512
d_ff = 2048
src_vocab_size = src_vocab_size
tgt_vocab_size = tgt_vocab_size
embedding_dim = 512
layer_number = 6
pos_len = 5
lr = 0.001

[train]
epoch = 100
batch_size = 10
shuffle = True

[data]
src_word2id_path =
tgt_word2id_path =
src_pretrain_path =
tgt_pretrain_path =

[output]
model_save_path =