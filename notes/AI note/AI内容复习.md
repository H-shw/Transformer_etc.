# AI内容复习

[toc]

## 数学知识

##### 凸函数 拉格朗日函数 KTT

https://zhuanlan.zhihu.com/p/38163970

## 基本概念与运用

##### 有监督学习和无监督学习

**有监督学习**算法**有训练过程**，算法用训练集进行学习，用学习得到的模型进行预测。通 常所见的机器学习应用，如图像识别、语音识别等都属于有监督学习问题。有监督学习的样本由输入值与标签值组成$(x,y)$ , 目标是找到映射函数 $y=h(x)$ 。

**无监督学**习对**无标签的样本**进行分析，发现样本集的结构或者分布规律。其典型代表是 **聚类**，表示学习，以及数据降维。表示学习也是无监督学习，样本中自动学习出有用的特征，用于分类或聚类任务。

聚类举例：

##### Kmeans

1. 定义 K 个重心。一开始这些重心是随机的（也有一些更加有效的用于初始化重心的算法）
2. 寻找最近的重心并且更新聚类分配。将每个数据点都分配给这 K 个聚类中的一个。每个数据点都被分配给离它们最近的重心的聚类。这里的「接近程度」的度量是一个超参数——通常是欧几里得距离（Euclidean distance）。
3. 将重心移动到它们的聚类的中心。每个聚类的重心的新位置是通过计算该聚类中所有数据点的平均位置得到的。

##### 神经网络中的无监督方法：AutoEcoder

它基于反向传播算法与最优化方法(如梯度下降法)，利用输入数据X本身作为监督,来指导神经网络尝试学习一个映射关系, 从而得到一个重构输出$x^R$。在时间序列异常检测场景下,异常对于正常来说是少数,所以我们认为，如果使用自编码器重构出来的输出$x^R$跟原始输入的差异超出一定阈值(threshold) 的
话，原始时间序列即存在了异常。

通过算法模型包含两个主要的部分: **Encoder** (编码器)和 **Decoder** (解码器)。

编码器的作用是把高维输入 $X$ 编码成低维的隐变量 $h$ 从而强迫神经网络学习最有信息量的特征;

解码器的作用是把隐藏层的隐变量h还原到初始维度,最好的状态就是解码器的输出能够完美地或者近似恢复出原来的输入,即 $x^R≈x$ .

![1.1.png](https://github.com/H-shw/Transformer_etc./blob/master/notes/AI%20note/pics/1.1.png?raw=true)

https://github.com/H-shw/Transformer_etc./blob/master/notes/AI%20note/pics/1.1.png

(1)从输入层->隐藏层的原始数据X的编码过程:
$h= g_{\theta_1}(x)=σ(W1x + b1)$

(2)从隐藏层->输出层的解码过程:

$\hat x= g_{\theta_2}(h)=σ(W_2h+b2)$

那么算法的优化目标函数就写为: $MinimizeLoss = dist(X, X^R)$
其中dist为二者的距离度量函数,通常用 MSE (均方方差)。

$MSE = \frac{1}{n}\sum_{i=1}^{m}w_i{(y_i-\hat{y_i})^{2}}$

自编码可以实现类似于PCA等数据降维、数据压缩的特性。从上面自编码的网络结构图，如果输入层神经元的个数n大于隐层神经元个数m,那么我们就相当于把数据从n维降到了m维;然后我们利用这m维的特征向量,进行重构原始的数据。

这个跟PCA降维一模一样,只不过PCA是通过求解特征向量,进行降维,是一种线性的降维方式，而自编码是一种非线性降维。

##### PCA

主成分分析是把多指标转化为少数几个综合指标。

主成分分析经常用减少数据集的维数，同时保持数据集的对方差贡献最大的特征。这是通过保留低阶主成分，忽略高阶主成分做到的。这样低阶成分往往能够保留住数据的最重要方面。

变换的步骤：

1. 第一步计算矩阵 X 的样本的[协方差矩阵](https://baike.baidu.com/item/协方差矩阵/9822183) S（此为不标准PCA，标准PCA计算[相关系数](https://baike.baidu.com/item/相关系数/3109424)[矩阵](https://easyai.tech/ai-definition/matrix/)C）(协方差的意义是，衡量两个变量偏差变化趋势是否一致，除以两变量标准差之积以标准化，即相关系数。https://blog.csdn.net/qq_23100417/article/details/84935692)
2. 第二步计算协方差矩阵S（或C）的[特征向量](https://baike.baidu.com/item/特征向量/8663983) **e**1,**e**2,…,**e**N和特征值 , t = 1,2,…,N
3. 第三步投影数据到特征向量张成的空间之中。利用下面公式，其中BV值是原样本中对应维度的值。

​	$newBV_{i,p}=\sum_{k=1}^{n} {e_{i}BV_{i,k}}$



##### 奇异值分解

假设*M*是一个*m×n*阶[矩阵](https://zh.wikipedia.org/wiki/矩陣)，其中的元素全部属于[域](https://zh.wikipedia.org/wiki/体_(数学))*K*，也就是[实数](https://zh.wikipedia.org/wiki/實數)域或[复数](https://zh.wikipedia.org/wiki/复数_(数学))域。如此则存在一个分解使得

其中*U*是*m×m*阶[酉矩阵](https://zh.wikipedia.org/wiki/酉矩陣)；Σ是*m×n*阶非负[实数](https://zh.wikipedia.org/wiki/实数)[对角矩阵](https://zh.wikipedia.org/wiki/對角矩陣)；而V\*，即*V*的[共轭转置](https://zh.wikipedia.org/wiki/共轭转置)，是*n×n*阶酉矩阵。这样的分解就称作*M*的**奇异值分解**。Σ 对角线上的元素Σ*i*,*i*即为*M*的**奇异值**。

https://zh.wikipedia.org/wiki/%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3

##### GAN

生成对抗网络（GAN）。它由两个网络组成：一个生成器和一个鉴别器，分别负责伪造图片和识别真假。

生成器产生图像的目的是诱使鉴别者相信它们是真实的，同时，鉴别者会因为发现假图片而获得奖励



##### 分类问题 与 回归问题

对于有监督学习，如果样本标签是整数则称为分类问题。此时的目标是确定样本的类别， 以整数编号。预测函数是向量到整数的映射。

如果标签值是连续实数则称为回归问题。此时预测函数是向量到实数的映射。

例如根据一个人的学历、工作年限等特征预测其收入，是典型的回归问题，收入是实数 值而不是类别标签。



##### 强化学习

强化学习模拟人的行为，源自于行为主义心理学。

类似于有监督学习，通过对状态-动作-回报值序列进行学习，可以得到一个称为策略函数的模型，用于确定在每种状态下要执行的动作。

训练时，对正确的动作做出奖励，对错误的动作进行惩罚，训练完成之后用得到 的模型进行预测。



##### 生成模型 与 判别模型

假设 $x$ 为特征向量，$y$ 为该样本的标签值。

如果机器学习算法对样本特征向量和标签的 联合概率分布 $p(x,y)$ 建模，则称为生成模型。

如果对条件概率 $p(y|x)$ 进行建模，则称为 判别模型。

不使用概率模型的分类算法也属于判别模型，它直接预测样本的标签值而不关心 样本的概率分布，这种情况的预测函数为 $y = f(x)$ 。

这三种模型也分别被称为生成学习，条件学习，以及判别学习。 

还有另外一种定义标准。生成模型对条件概率 $p(x|y)$ 建模，判别模型对条件概率 $p(y|x) $建模。前者不仅可以通过贝叶斯公式用于分类问题，还可用于根据标签值 y （也称 为隐变量）生成随机的样本数据 x ，而后者则只能用于根据样本特征向量 x 的值判断它的标签值 y 的分类任务。

**生成模型**： 学习时先得到 P(x,y)，继而得到 P(y|x)。预测时应用最大后验概率法（MAP）得到预测类别 y 。

MAP : https://blog.csdn.net/gcheney/article/details/108442861

https://blog.csdn.net/fq_wallow/article/details/104383057

**判别模型**： 直接学习得到P(y|x)，利用MAP得到 y。或者直接学得一个映射函数 y = f(x)。

##### 过拟合

模型在训练集上精度高，但在测试集上精度低。

##### 过拟合的原因有哪些

 引起过拟合的可能原因有：

1. 模型本身过于复杂，拟合了训练样本集中的噪声。此时需要选用更简单的模型，或 者对模型进行裁剪。 
2.  训练样本太少或者缺乏代表性。此时需要增加样本数，或者增加样本的多样性。 
3.  训练样本噪声的干扰，导致模型拟合了这些噪声，这时需要剔除噪声数据或者改用 对噪声不敏感的模型。

##### 正则化方法

- **正则化(Regularization)** 是机器学习中对原始损失函数引入额外信息，以便防止过拟合和提高模型泛化性能的一类方法的统称。也就是目标函数变成了**原始损失函数+额外项**，常用的额外项一般有两种，中文称作**L1正则化**和**L2正则化**，或者L1范数和L2范数（实际是L2范数的平方）。
- L1正则化和L2正则化可以看做是**损失函数的惩罚项**。所谓**惩罚**是指对损失函数中的**某些参数做一些限制**。对于线性回归模型，**使用L1正则化的模型叫做Lasso回归，使用L2正则化的模型叫做Ridge回归（岭回归）**。
- https://www.cnblogs.com/zingp/p/10375691.html

L1 正则化 

L2 正则化 

- L1正则化是指权值向量w中各个元素的绝对值之和，通常表示为∥w∥1
- L2正则化是指权值向量w中各个元素的平方和然后再求平方根（可以看到Ridge回归的L2正则化项有平方符号），通常表示为∥w∥2
- L2防止过拟合的原因：**拟合过程中通常都倾向于让权值尽可能小**，最后构造一个所有参数都比较小的模型。因为一般认为参数值小的模型比较简单，能适应不同的数据集，也在一定程度上避免了过拟合现象。**可以设想一下对于一个线性回归方程，若参数很大，那么只要数据偏移一点点，就会对结果造成很大的影响；但如果参数足够小，数据偏移得多一点也不会对结果造成什么影响**，专业一点的说法是**抗扰动能力强**。
- $\theta_{j} = \theta_{j}(1-\alpha\frac{\lambda}{n})-\alpha\frac{1}{n}\sum_{i=1}^{n}(h\theta(x^{(i)})-y^{(i)})x_{j}^{(i)}$
- **其中λ就是正则化参数**。从上式可以看到，与未添加L2正则化的迭代公式相比，每一次迭代，θj 都要先乘以一个小于1的因子，从而使得θj不断减小，因此总得来看，θ是不断减小的。
  最开始也提到L1正则化一定程度上也可以防止过拟合。之前做了解释，当L1的正则化系数很小时，得到的最优解会很小，可以达到和L2正则化类似的效果。

决策树的剪枝算法 

神经网络训练中的 dropout 技术

提前终止技术

##### ROC 曲线的原理

 对于二分类问题可以通过调整分类器的灵敏度得到不同的分类结果，从而在二者之间折中。将各种灵敏度下的性能指标连成曲线可以得到 ROC 曲线，它能够更全面的反映算法的性能。 

真阳率（TPR）即召回率，是正样本被分类器判定为正样本的比例。

$TPR = TP /(TP + FN)$

在目标检测任务中正样本是要检测的目标，真阳率即检测率，即目标能够被检测出来的 比例。

假阳率（FPR）是负样本被分类器判定为正样本的比例

$FPR = FP /(FP + TN)$ 

对于目标检测问题假阳率即误报率。 

ROC 曲线的横轴为假阳率，纵轴为真阳率。当假阳率增加时真阳率会增加，它是一条增长的曲线

##### AUC

ROC曲线下方的面积（英语：Area under the Curve of ROC (AUC ROC)），其意义是：

- 因为是在1x1的方格里求面积，AUC必在0~1之间。
- 假设阈值以上是阳性，以下是阴性；
- 若随机抽取一个阳性样本和一个阴性样本，分类器**正确判断**阳性样本的值高于阴性样本之**概率**。
- 简单说：**AUC值越大的分类器，正确率越高。**

从AUC判断分类器（预测模型）优劣的标准：

- AUC = 1，是完美分类器，采用这个预测模型时，存在至少一个阈值能得出完美预测。绝大多数预测的场合，不存在完美分类器。
- 0.5 < AUC < 1，优于随机猜测。这个分类器（模型）妥善设置阈值的话，能有预测价值。
- AUC = 0.5，跟随机猜测一样（例：丢铜板），模型没有预测价值。
- AUC < 0.5，比随机猜测还差；但只要总是反预测而行，就优于随机猜测。

![1.2.png](https://github.com/H-shw/Transformer_etc./blob/master/notes/AI%20note/pics/1.2.png?raw=true)

##### 精度，召回率，F1 值

精度：$P = \frac{TP}{TP+FP}$

召回率：$R=\frac{TP}{TP+FN}$

同样的 R <= 1。精度值越接近 1，对正样本的分类越准确，即查的越准。召回率越接近于1，正样本被正确分类的比例越大，即查的越全。 根据精度和召回率，F1 值定义为

$F1 = \frac{2PR}{P+R}$

是精度和召回率的调和平均数的倒数

$\frac{1}{F1}=\frac{1}{2}(\frac{1}{P}+\frac{1}{R})$

##### 交叉验证的原理

 交叉验证用于统计模型的精度值。k 折交叉验证将样本随机、均匀地分为 k 份，轮流用 其中的 k -1份训练模型，1 份用于测试模型的准确率，用 k 个准确率的均值作为最终的准确率。

##### 过拟合 是欠拟合

欠拟合也称为欠学习，指模型在训练集上的精度差。导致欠拟合的常见原因有模型简单， 特征数太少无法正确的建立映射关系。 

过拟合也称为过学习，指模型在训练集上表精度高，但在测试集上精度低，泛化性能差。 

过拟合产生的根本原因是训练数据包含抽样误差，算法训练时模型拟合了抽样误差。所谓抽样误差，是指抽样得到的样本集和整体数据集之间的偏差。

##### 没有免费午餐定理

没有任何一个机器学习模型在所有样本集上表现是最优的。如果在一个数据集上算法 A 优于算法 B，则一定存在另外一个数据集，使得 B 优于 A

##### 奥卡姆剃刀原理

简单的模型通常具有更好的泛化性能

##### 神经网络训练时的目标函数是否为凸函数

一般情况下不是凸函数。因此面临局部极小值和鞍点问题。

**凸问题的局部最优解就是全局最优解**。

##### 凸函数与凸优化

[理解凸优化 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/37108430)

##### 混淆矩阵的概念

对于 k 分类问题，混淆矩阵为 k * k 的矩阵，它的元素 $c_{ij}$ 表示第i 类样本被分类器判定 为第 j 类的数量。

对角线上即为划分正确的元素。

##### 贝叶斯 先验概率 后验概率

如果事件 A 是因，事件 B 是果，则称 p(A) 为 先验概率，意为事先已经知道其值。 

p (A|B) 称为后验概率，意为事后才知道其值。

条件概率 p(B|A) 则称为似然函数。

先验概率是根据以往经验和分析得到的概率，在随机事件发生之前即已经知道，是“原因”发生的概率。后验概率是根据“结果”信息所计算出的导致该结果的原因所出现的概率。

后验概率用于在事情已经发生的条件下，分析使得这件事情发生的原因概率。

##### 贝叶斯 拉普拉斯光滑

在类条件概率的计算公式中，如果 , $N_{x_{i}=v,y=c}$ 为 0，即特征分量的某个取值在某一类在训 练样本中一次都不出现，则会导致如果预测样本的特征分量取到这个值时**整个分类判别函数 的值为 0**。

作为补救措施可以使用拉普拉斯平滑，具体做法是给分子和分母同时加上一个正 数。如果特征分量的取值有 k 种情况，将分母加上 k ，每一类的分子加上 1，这样可以保证 所有类的条件概率加起来还是 1



##### 决策树

[决策树(Decision Tree)：通俗易懂之介绍 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/30059442)

CART 指标

Gini 不纯度。样本集的 Gini 不纯度定义：$G(D)=1-\sum_{i}p_{i}^{2}$

C4.5

$GR = \frac{G}{IV}$

其中 $IV=-\sum_{i=1}^{m}\frac{|D_i|}{|D|}ln\frac{|D_i|}{|D|}$

对于分类问题，叶子节点的值如何设定？对于回归问题，决策树叶子节点的值如何设定？

对于分类树，将叶子节点的值设置成本节点的训练样本集中出现概率最大的那个类。即

$y^{*}=arg\,\,max_{y}p_{y}$

对于回归树，则设置为本节点训练样本标签值的均值

$y^{*}=\frac{\sum_{i=1}^{N}y_{i}}{N}$



##### 决策树 预剪枝 后剪枝

决策树的剪枝算法可以分为两类，分别称为预剪枝和后剪枝。前者在树的训练过程中通 过停止分裂对树的规模进行限制；后者先构造出一棵完整的树，然后通过某种规则消除掉部 分节点，用叶子节点替代。

##### 决策树 属性缺失

在某些情况下样本特征向量中一些分量没有值，这称为属性缺失

#####  k 的取值对 k 近邻算法的影响。

如果其值太小，则容易受到噪声的影响，导致泛函性能下降，出现过拟合。

如果 k 值等 于训练样数，则对于任意的预测样本，都会将其预测为训练样本集中数量最大的类

##### KNN用于

k 近邻算法也可以用于回归问题。假设离测试样本最近的 k 个训练样本的标签值为 i y ， 则对样本的回归预测输出值为
$$
\hat{y} = (\sum_{i=1}^{k}y_{i})/k
$$

##### 各种距离

![1.1.3.png](https://github.com/H-shw/Transformer_etc./blob/master/notes/AI%20note/pics/1.1.3.png?raw=true)

##### LMNN 算法

LMNN 寻找一个变换矩阵，使得变换后每个样本的个最近邻居都和它是同一个类，而不 同类型的样本通过一个大的间隔被分开。

参考习题答案与[大间隔最近邻居_百度百科 (baidu.com)](https://baike.baidu.com/item/大间隔最近邻居/)

##### 数据降维

使用数据降维算法的目的是什么？ 数据降维算法的目标是将向量变换到低维空间中，并保持原始空间中的某些结构信息， 以达到某种目的，如避免维数灾难，数据可视化。

##### 解释 PCA 降维算法的流程

计算投影矩阵的流程： 

1.计算样本集的均值向量。将所有向量减去均值，这称为白化。 

2.计算样本集的协方差矩阵。 

3.对方差矩阵进行特征值分解，得到所有特征值与特征向量。 

4.将特征值从大到小排序，保留最大的一部分特征值对应的特征向量，以它们为行，形成投影矩阵。 

投影算法的流程： 

1.将样本减掉均值向量。 

2.左乘投影矩阵，得到降维后的向量

 PCA 重构算法的流程。

#####  向量重构的流程为：

1.输入向量左乘投影矩阵的转置矩阵。 

2.加上均值向量，得到重构后的结果。

##### 神经网络 激活函数

保证神经网络的映射是非线性的，如果不使用激活函数，无论神经网络有多少层，其所 表示的复合函数还是一个线性函数。

激活函数需要满足： 

1.非线性。保证神经网络实现的映射是非线性的。 

2.几乎处处可导。保证可以用梯度下降法等基于导数的算法进行训练。 

3.单调递增或者递减。保证满足万能逼近定理的要求，且目标函数有较好的特性。

##### sigmoid

$f(x)=\frac{1}{1+e^{-x}}$

$f^{'}(x)=f(x)(1-f(x))$

##### 神经网络参数的初始值如何设定？ 

一般用随机数进行初始化 或者 预训练

**Xavier初始值（sigmod、tanh等S型曲线的权重初始值）**

Xavier等人发现，为了使各层的激活值呈现出具有相同广度的分布，推导了合适的权重尺度。推导出的结论是，如果前一层的节点数为n，则初始值使用标准差为 $\frac{1}{\sqrt{n}}$ 的分布。

**He初始值（ReLU的权重初始值）**

当前一层的节点数为n时，He初始值使用标准差为 $\sqrt{\frac{2}{n}}$ 的高斯分布。

##### 梯度消失

什么是梯度消失问题，为什么会出现梯度消失问题？ 在用反向传播算法计算误差项时每一层都要乘以本层激活函数的导数。

$\delta^{l}=(W^{l+1})^{T}\delta^{(l+1)}\odot f'(u^{(l)})$

如果激活函数导数的绝对值小于 1，多次连乘之后误差项很快会衰减到接近于 0，参数 的梯度值由误差项计算得到，从而导致前面层的权重梯度接近于 0，参数无法有效的更新， 称为梯度消失问题.

##### 动量项的原理

动量项累积了之前的权重更新值，加上此项之后的参数更新公式为 

$W_{t+1} = W_{t} + V_{t+1} $

其中$V_{t+1} $是动量项，计算公式为

$V_{t+1}=-\alpha\triangledown _{W}L(W_t)+\mu V_t$

它是上一时刻的动量项与本次梯度值的加权平均值，其中 $\alpha$ 是学习率， $\mu$ 是动量项 数。如果按照时间 t 进行展开，则第 t 次迭代时使用了从 1 到t 次迭代时的所有梯度值，且老 的梯度值按照 $\mu^{t}$ 的系数指数级衰减。动量项是为了加快梯度下降法的收敛，它使用历史信息对当前梯度值进行修正，以抵消在病态条件问题上的来回震荡。

## 机器学习基本模型

### 感知机

##### 简单介绍

适用于线性可分性的数据和任务
$$
f(x)=sign(w⋅x+b)\\\\
\begin{equation}
f(x)=\left\{
\begin{aligned}
+1 ,\quad x \ge0\\
-1 ,\quad x<0\\
\end{aligned}
\right.
\end{equation}
$$
对应于特征空间$R^n$中的一个超平面 $S$ ，其中**$w$是超平面的法向量**，$b$ 是超平面的截距。这个超平面将特征空间划分为两个部分。位于两部分的点（特征向量）分别被分为正、负两类。因此，超平面$S$称为分离超平面。

![1.3.png](https://github.com/H-shw/Transformer_etc./blob/master/notes/AI%20note/pics/1.3.png?raw=true)

##### Loss

$L(w,b)=-\sum_{x_{i}\in M}y_{i}(w⋅x_{i}+b)$

##### 普通形式

输入：**线性可分**的训练数据集$T={(x_1,y_1),(x_2,y_2),...,(x_N,y_N)}$，其中，$x$属于$R^n$ 空间，$y$ 属于 ${+1,-1}$ 空间；学习率 $\eta(0<\eta\leqslant 1)$ ；

输出：w、b；感知机模型 $f(x)=\text{sign}(w\cdot x+b)$ 。

（1）选取初始 $w_0$ 、$b_0$

（2）在训练集中选取数据 $(x_i,y_i)$

（3）如果 $y_i(w\cdot x_i+b)\leqslant 0$

$$
\begin{aligned} w&\leftarrow w+\eta y_ix_i\\
b&\leftarrow b+\eta y_i \end{aligned}
$$
（4）转至（2），直至训练集中没有误分类点。

##### 感知机学习算法的对偶形式：

逐步修改w、b，设修改n次，则w，b关于 $(x_i, y_i)$ 的增量分别是$\alpha_i\cdot y_i\cdot x_i$ 和$\alpha_i\cdot y_i$，这里$\alpha_i=n_i\eta$，其中，$n_i$是每个点的累计修改次数，所以每个点的修改次数加起来就是总的修改次数n，即$n_i$ 满足

$\sum_{i=1}^Nn_i=ni=1$

其中，n 为总的修改次数。

输入：**线性可分**的数据集

$T={(x_1,y_1),(x_2,y_2),...,(x_N,y_N)}$

其中，$x$ 属于$R^n$空间，y属于${+1,-1}$空间；学习率$\eta(0<\eta \leqslant 1)$ ；

输出：$α、b$；感知机模型

$f(x)=\text{sign}(\sum_{j=1}^N\alpha_j \cdot y_j \cdot x_j \cdot x+b)$

其中，

$\alpha=(\alpha_1,\alpha_2,...,\alpha_N)^T$

（1）$\alpha\leftarrow 0$，$b\leftarrow 0$

（2）在训练集中选取数据$(x_i,y_i)$

（3）如果$y_i(\sum_{j=1}^N\alpha_jy_jx_j\cdot x_i+b)\leqslant 0$，则
$$
\begin{aligned} 
\alpha_i&\leftarrow \alpha_i+\eta\\
b&\leftarrow b+\eta y_i 
\end{aligned}
$$


（4）转至（2），直至训练集中没有误分类点。

对偶形式中训练实例仅以内积的形式出现。为了方便，可以预先将训练集中实例间的内积计算出来，并以矩阵的形式存储，这个矩阵就是所谓的**Gram矩阵**。(暂存 $x_i,y_i$ 的数据)，可以暂存计算结果，加快速度。



### K邻近

##### 普通

k近邻算法简单、直观：给定一个训练数据集，对新的输入实例，在训练数据集中找到与该实例最邻近的k个实例，这k个实例的多数属于某个类，就把该输入实例分为这个类。

**输入**：训练数据集

$T={(x_1,y_1),(x_2,y_2),...,(x_N,y_N)}$

其中，$x_i\in R^n$为实例的特征向量，$y_i\in \{c_1,c_2,...,c_K\}$为实例的类别；实例特征向量$x$；

**输出**：实例$x$所属的类$y$。

（1）根据给定的距离度量，在训练集$T$中找出与$x$最临近的几个点，涵盖这$k$个点的$x$的邻域记作$N_k(x)$；

（2）在$N_k(x)$中根据分类决策规则（如多数表决）决定$x$的类别 $y$：

$y=\text{arg}\ \mathop{\text{max}}_{c_j}\ \sum_{x_i\in N_k(x)}I(y_i=c_j),\ i=1,2,...,N;\ j=1,2,...,K$

上式中的I为指示函数，即当$y_i=c_j$ 时I 为1，否则 I 为0。

k近邻法**没有显式的学习过程**，它实际上利用训练数据集对特征向量空间进行划分，并作为其分类的“模型”。

##### 数据归一化：

由于数据的各个特征的量纲不同，可能会导致某个特征的重要性远远大于其他特征，这是不客观的，所以我们应该让每个特征都是同等重要的。

这也是我们在计算距离时要对数据进行归一化的原因。归一化公式如下：

一般来说，假设进行kNN分类使用的样本特征（ n 维）是

${(x_i^{(1)},x_i^{(2)},...,x_i^{(n)})},\ i=1,2,...,m$

，取每一轴上的最大值最小值

$M_j=\mathop{\text{max}}_{i=1,...,m}x_{ij}-\mathop{\text{min}}_{i=1,...,m}x_{ij}$

，并且在计算距离时将每一个坐标轴除以相应的M_jMj进行归一化，即

$d((y_1,...,y_n),(z_1,...,z_n))=\sqrt{\sum_{j=1}^n(\frac{y_j}{M_j}-\frac{z_j}{M_j})^2}$



**K值选取的影响基本概念那边那栏**

##### 改进策略1：高斯函数对距离加权

高斯函数：$f(x)=ae^{-\frac{(x-b)^2}{2c^2}}$

使用时将 $x-b$ 认为是距离 ， $c$ 是 要调的超参数。

```python
def Gaussian(distance, sigma = 9.0):
    """ Input a distance and return it`s weight"""
    weight = np.exp(-distance**2/(2*sigma**2))
    return weight
```



![1.4.png](https://github.com/H-shw/Transformer_etc./blob/master/notes/AI%20note/pics/1.4.png?raw=true)

最后选择加权求和后最大的一类。

##### KD树

常规的k-d tree的构建过程为：循环依序取数据点的各维度来作为切分维度，取数据点在该维度的中值作为切分超平面，将中值左侧的数据点挂在其左子树，将中值右侧的数据点挂在其右子树。递归处理其子树，直至所有数据点挂载完毕。 

**a）切分维度选择优化** 构建开始前，对比数据点在各维度的分布情况，数据点在某一维度坐标值的方差越大分布越分散，方差越小分布越集中。从方差大的维度开始切分可以取得很好的切分效果及平衡性。 

**b）中值选择优化** 

* 第一种，算法开始前，对原始数据点在所有维度进行一次排序，存储下来，然后在后续的中值选择中，无须每次都对其子集进行排序，提升了性能。 

* 第二种，从原始数据点中随机选择固定数目的点，然后对其进行排序，每次从这些样本点中取中值，来作为分割超平面。该方式在实践中被证明可以取得很好性能及很好的平衡性。 

采用常规的构建方式，以二维平面点(x,y)的集合(2,3)，(5,4)，(9,6)，(4,7)，(8,1)，(7,2)为例。 

**a）**构建根节点时，此时的切分维度为x，如上点集合在x维从小到大排序为(2,3)，(4,7)，(5,4)，(7,2)，(8,1)，(9,6)；其中值为(7,2)。（注：2,4,5,7,8,9在数学中的中值为(5 + 7)/2=6，但因该算法的中值需在点集合之内，所以本文中值计算用的是len(points)/2=3, points[3]=(7,2)）

 **b）**(2,3)，(4,7)，(5,4)挂在(7,2)节点的左子树，(8,1)，(9,6)挂在(7,2)节点的右子树。 

**c）**构建(7,2)节点的左子树时，点集合(2,3)，(4,7)，(5,4)此时的切分维度为y，中值为(5,4)作为分割平面，(2,3)挂在其左子树，(4,7)挂在其右子树。 

**d）**构建(7,2)节点的右子树时，点集合(8,1)，(9,6)此时的切分维度也为y，中值为(9,6)作为分割平面，(8,1)挂在其左子树。至此k-d tree构建完成。

![1.5.png](https://github.com/H-shw/Transformer_etc./blob/master/notes/AI%20note/pics/1.5.png?raw=true)

上述的构建过程结合下图可以看出，构建一个k-d tree即是将一个二维平面逐步划分的过程。

![1.6.png](https://github.com/H-shw/Transformer_etc./blob/master/notes/AI%20note/pics/1.6.png?raw=true)

KD 树主要用于搜索，可以快速找到邻近的点。

给定一个构建于一个样本集的kd树，下面的算法可以寻找距离某个点p最近的k个样本。

- **a**：设L为一个有k个空位的列表，用于保存已搜寻到的最近点。

- **b**：根据p的坐标值和每个节点的切分向下搜索（也就是说，如果树的节点是照xr进行切分，并且p的r坐标小于a，则向左枝进行搜索；反之则走右枝）。

- **c**：**当达到一个底部节点时，将其标记为访问过**。如果L里不足k个点，则将当前节点的特征坐标加入L ；如果L不为空并且当前节点的特征与p的距离小于L里最长的距离，则用当前特征替换掉L中离p最远的点。(最底层找符合目标的点加入

- **d**

  **如果当前节点不是整棵树最顶端节点，执行(e)**；反之，输出L，算法完成。

  - **e**. 向上爬一个节点。如果当前（向上爬之后的）节点未曾被访问过，将其标记为被访问过，然后执行(1) 和(2)；如果当前节点被访问过，再次执行(e)。
  - **1**.如果此时L里不足k个点，则将节点特征加入L；如果L中已满k个点，且当前节点与p的距离小于L里最长的距离，则用节点特征替换掉L中离最远的点。
  - **2**.**计算p和当前节点切分线的距离。**如果该距离大于等于L中距离p最远的距离并且L中已有k个点，则在切分线另一边不会有更近的点，执行(c)；如果该距离小于L中最远的距离或者L中不足k个点，则切分线另一边可能有更近的点，因此在当前节点的另一个枝从(a)开始执行。



### 线性回归(linear regression)

##### 回归与分类的差别

输出是离散还是连续，离散即为分类，连续即为回归。

在说分类与回归的区别之前，先说下分类与回归的相同之处：都属于“监督学习（supervised learning）”，从数学的角度来说，监督学习是一个映射，它存在输入空间和输出空间，分别对应机器学习里常说的样本和标记。

这就是分类问题和回归问题的区别所在，仅仅通过判断输出值是离散的还是连续的就可以确定；

不能把分类标签当回归问题的输出来解决，所以分类和回归的**损失函数**也不一样，分类的损失函数一般用交叉熵这种，而回归的损失函数一般用类似平方误差这种。

##### 方法

即用 $y=ax+b$ 拟合数据点

##### Loss 更新参数方法

1.梯度下降的方法
$$
\alpha = \alpha-\alpha\frac{\delta cost(a,b)}{\delta a}\\
b = b-b\frac{\delta cost(a,b)}{\delta b}
$$
每次更新的学习率应当下降，直至收敛。

2.最小二乘法

https://zhuanlan.zhihu.com/p/38128785

具体举例：

![1.7.png](https://github.com/H-shw/Transformer_etc./blob/master/notes/AI%20note/pics/1.7.png?raw=true)

两者差别

![1.8.png](https://github.com/H-shw/Transformer_etc./blob/master/notes/AI%20note/pics/1.8.png?raw=true)

### Logistic回归

**是分类任务**

使用类似 *sigmoid* 拟合数据。

sigmoid

![1.9.png](https://github.com/H-shw/Transformer_etc./blob/master/notes/AI%20note/pics/1.9.png?raw=true)

使用的模型：
$$
\frac{1}{1 +e^{-(wx+b)}}
$$
通过调整w、b的值，可以让模型不断改变以匹配数据点。

使用 MSE 得到的 Loss 函数关于w、b是**非凸**的，这就意味着代价函数有着许多的局部最小值。



可以用**交叉熵**作为 Loss, 在这里是凸函数。(MLE准则导出的损失函数与交叉熵损失函数等价)

https://zhuanlan.zhihu.com/p/115277553

二分类：$l(\theta)=ylog(\hat{y})+(1-y)log({1-\hat{y}})$

多分类时，除了正确的那个类的指示函数是 0 ，其他都是1

多分类可以采用 softmax

是 $softmax(z_i)=\frac{exp(z_i)}{\sum_jexp(z_j)}$

### 决策树

![1.10.png](https://github.com/H-shw/Transformer_etc./blob/master/notes/AI%20note/pics/1.10.png?raw=true)



##### ID3

特征 A 对训练数据集 D 的信息增益 g(D,A)，定义为集合 D 的经验熵 H(D) 与特征 A 给定条件下 D 的条件经验熵 $H(D|A)$ 之差，即

$g(D,A)=H(D)-H(D|A)$

熵 H(Y) 与条件熵 H(Y|X) 之差称为互信息。决策树学习中的信息增益等价于训练数据集中类与特征的互信息。

**信息增益表示得知特征 X 的信息而使类 Y 的信息的不确定性减少的程度**。一般而言，信息增益越大，意味着使用属性aa来进行划分所获得的“纯度提升”越大，因此，我们可用信息增益来进行决策树的划分属性的选择。选择信息增益最大的属性，即在上图的决策树学习算法的第8行选择属性 $a^*$ 。

$a_*=\text{arg}\ \mathop{\text{max}}_{a\in A}\ \text{Gain}(D,a)$

**信息增益的算法：**

输入：训练数据集 D 和特征 A ；

输出：特征A 对训练集 D 的信息增益 g(D,A) 。

（1）计算数据集DD的经验熵H(D)

$H(D)=-\sum_{k=1}^K\frac{|C_k|}{|D|}\text{log}_2\frac{|C_k|}{|D|}$


（2）计算特征AA对数据集DD的经验条件熵H(D|A)

$H(D|A)=\sum_{i=1}^n\frac{|D_i|}{|D|}H(D_i)=-\sum_{i=1}^n\frac{|D_i|}{|D|}\sum_{k=1}^K\frac{|D_{ik}|}{D_i}$


（3）计算信息增益

$g(D,A)=H(D)-H(D|A)$


##### C4.5

目的是防止过拟合。

**信息增益率的定义**

特征 A 对训练数据 D 的信息增益率 $g_R(D,A)$ 定义为其信息增益 $g(D,A)$与其训练数据集 D 关于特征 A 的值的熵 $H_A(D)$ 之比，即

$g_R(D,A)=\frac{g(D,A)}{H_A(D)}$

其中，$H_A(D)=-\sum_{i=1}^n\frac{|D_i|}{|D|}\text{log}_2\frac{|D_i|}{|D|}$，n 是特征 A 取值的个数。

上式表明，一个特征的取值越多，则其本身的熵越大。



##### CART

“基尼不纯度”（Gini impurity）来选择划分属性。数据集 D 的纯度可以用基尼不纯度来度量：

分类问题中，假设有 K 个类，样本点属于第 k 类的概率为 $p_k$ ，则概率分布的基尼不纯度定义为
$$
\begin{aligned} 
\text{Gini}(D)&=\sum_{k=1}^{K}\sum_{k'\neq k}p_kp_{k'}\\
&=\sum_{k=1}^{K}p_k(1-p_k)\\
&=1-\sum_{k=1}^{K}p_k^2 
\end{aligned}
$$


直观的来说，Gini(D)反映了**从数据集 D 中随机抽取两个样本，其类别标记不一致的概率**。因此，Gini(D)越小，则数据集 D 的纯度越高。

对于给定的样本集合 D ，其基尼不纯度为

$\text{Gini}(D)=1-\sum_{k=1}^K\left(\frac{|C_k|}{|D|}\right)^2$

这里，$C_k$ 是 D 中属于第 $k$ 类的样本子集， $K$ 是类的个数。

如果样本集合DD根据特征AA是否取某一可能值aa被分割成D_1D1和D_2D2两部分，则在特征AA的条件下，集合DD的基尼不纯度定义为

$\text{Gini}(D,A)=\frac{|D_1|}{|D|}\text{Gini}(D_1)+\frac{|D_2|}{|D|}\text{Gini}(D_2)$ 

基尼不纯度 Gini(D) 表示集合 D 的不确定性，基尼不纯度Gini(D,A)表示经A=a 分割后，集合的不确定性。指数越大，样本的集合不确定性越大，这一点与熵类似。

决策树生成算法递归地产生决策树，直到不能继续下去为止。这样产生的树往往对训练数据的分类很准确，但对未知的测试数据的分类却没有那么准确，即出现过拟合现象。解决这个问题的办法是考虑决策树的复杂度，对已经生成的决策树进行简化。

##### 剪枝

剪枝从已经生成的树上裁掉一些子树或者叶结点，并将其根结点或父结点作为新的叶结点，从而简化分类树模型。

决策树剪枝的基本策略有“预剪枝”和“后剪枝”两种：**预剪枝**(pre prune)：先设定好规则，一旦数据符合这个规则就被剪枝；**后剪枝**(post prune): 子树替换，子树提升。

- **预剪枝**是指在决策树生成过程中，对每个结点在划分前先进行估计，若当前结点的划分不能带来决策树泛化性能（验证集准确率）的提升，则停止划分并将当前结点标记为叶结点；
- **后剪枝**则是先从训练集生成一棵完整的决策树，然后自底向上地对非叶结点进行考察，若将该结点对应的子树替换为叶结点能带来决策树泛化性能提升，则将该子树替换为叶结点。

如何判断决策树泛化性能（验证集准确率）是否提升呢？

这里采用留出法，**即预留一部分数用作“验证集”进行性能评估**。

**预剪枝**

![1.11.png](https://github.com/H-shw/Transformer_etc./blob/master/notes/AI%20note/pics/1.11.png?raw=true)

可以看出，预剪枝决策树使得决策树的很多分支都没有“展开”，这不仅降低了过拟合的风险，还显著少了决策树的训练时间开销和测试时间开销。

但另一方面，有些分支的当前划分虽不能提升泛化性能、甚至可能导致泛化性能暂时下降，但在其基础上进行的后续划分，却有可能导致性能显著提高；

预剪枝基于**“贪心”**禁止这些分支展开，给预剪枝决策树带来了**欠拟合**的风险。

**后剪枝**

首先构造完整的决策树，允许树过度拟合数据，然后应单个结点代替子树，节点的分类采用子树的主要分类。剪枝方法有错误率降低剪枝，悲观错误剪枝，代价复杂度剪枝。

后剪枝需要有验证集参与。

![1.12.png](https://github.com/H-shw/Transformer_etc./blob/master/notes/AI%20note/pics/1.12.png?raw=true)

后剪枝决策树通常比预剪枝决策树保留了更多的分支。

一般情形下，后剪枝决策树的欠拟合风险很小，泛化性能往往优于预剪枝决策树。

但后剪枝过程是在生成完全决策树之后进行的，并且要自底向上地对树中的所有非叶结点进行逐一考察，因此其训练时间开销比未剪枝决策树和预剪枝决策树都要大得多。

**连续值处理**
到目前为止我们仅讨论了基于离散属性来生成决策树。现实学习任务中常会遇到连续属性，有必要讨论如何在决策树学习中使用连续属性。

由于连续属性的可取值数目不再有限，因此，不能直接根据连续属性的可取值来对结点进行划分。此时，连续属性离散化技术可派上用场。**最简单**的策略是采用**二分法**(bi-partition)对连续属性进行处理，这正是C4.5决策树算法中采用的机制。

给定样本集DD和连续属性 A ，假定A 在D 上出现了 n 个不同的取值，将这些值从小到大进行排序，记为$\{a^1,a^2,...,a^n\}$。基于划分点t 可将D 分为子集$D_t^-$ 和$D_t^+$ ，其中 $D_t^-$ 包含那些在属性aa上取值不大于t 的样本，而$D_t^+$ 则包含那些在属性a上取值大于t 的样本。显然，对相邻的属性取值$a^i$
 与 $a^{i+1}$ 来说，t 在区间$[a^i,a^{i+1})$ 中取任意值所产生的划分结果相同。

因此，对连续属性 A  ，我们可考察包括 n-1 个元素的候选划分点集合

$T_a=\left\{\frac{a^i+a^{i+1}}{2}|1\leqslant i \leqslant n-1\right\}$
，即把区间的中位点 $\frac{a^i+a^{i+1}}{2}$ 作为候选点划分。然后，我们就可以像离散属性值一样来考察这些划分点，选取最优的划分点进行样本集合的划分。

### 支持向量机

支持向量机学习方法包含构建由简至繁的模型：

* 线性可分支持向量机（ linear support vector machine in linearly separable case )、

* 线性支持向量机（ linear support vector machine)

* 非线性支持向量机（non-linear support vector machine)。

简单模型是复杂模型的基础，也是复杂模型的特殊情况。

当训练数据线性可分时，通过硬间隔最大化（ hard margin maximization)，学习一个线性的分类器，即线性可分支持向量机，又称为硬间隔支持向量机；

当训练数据近似线性可分时，通过软间隔最大化（ soft margin maximization)，也学习一个线性的分类器，即线性支持向量机，又称为软间隔支持向量机；

当训练数据线性不可分时，通过使用核技巧（kemel trick）及软间隔最大化，学习非线性支持向量机。

#### 线性可分支持向量机

假设给定一个特征空间上的训练数据集

$T=\{ (x_1,y_1),(x_2,y_2),...,(x_N,y_N) \}$

其中，$x_i\in X=R^n$，$y_i\in Y=\{+1,-1\}, i=1,2,...,N$，$x_i$为第 i 个特征向量，也称为实例，$y_i$ 为$x_i$ 的类标记，当 $y_i=+1$ 时，称 $x_i$ 为正例；当 $y_i=-1$ 时，称 $x_i$ 为负例，$(x_i,y_i)$ 称为样本点。再假设训练数据集是线性可分的。

学习的目标是在特征空间中找到一个分离超平面，能将实例分到不同的类。分离超平面对应于方程$w\cdot x+b=0$ ，它由法向量 w 和截距 b 决定，可用 (w,b) 来表示。分离超平面将特征空间划分为两部分，一部分是正类，一部分是负类。法向量指向的一侧为正类，另一侧为负类。

一般地，当训练数据集线性可分时，存在无穷个分离超平面可将两类数据正确分开。感知机利用误分类最小的策略，求得分离超平面，不过这时的解有无穷多个。**线性可分支持向量机利用间隔最大化求最优分离超平面**。

**函数间隔**

在上图中，有A,B,C三个点，表示三个实例，均在分离超平面的正类一侧，预测他们的类。点A距分离超平面较远，若预测该点为正类，就比较确信预测是正确的；点C距分离超平面较近，若预测该点为正类就不那么确信；点B介于点A与C之间，预测其为正类的确信度也在A与C之间。

一般来说，**一个点距离分离超平面的远近可以表示分类预测的确信程度**。

对于给定的训练数据集TT和超平面 (w,b) ，定义超平面(w,b) 关于样本点 $(x_i,y_i)$ 的几何间隔为

$\gamma_i=y_i\left(\frac{w}{||w||}\cdot x_i+\frac{b}{||w||}\right)$

定义超平面 $(w,b)$ 关于训练数据集 T 的几何间隔为超平面 (w,b) 关于T 所有样本点 $(x_i,y_i)$ 的几何间隔之最小值，即

$\gamma=\mathop{\text{min}}_{i=1,...,N}\gamma_i$

超平面 (w,b) 关于样本点 $(x_i,y_i)$ 的几何间隔一般是实例点到超平面的带符号的距离（signed distance），当样本点被超平面正确分类时就是实例点到超平面的距离。

从函数间隔和几何间隔的定义可知，函数间隔和几何间隔有下面的关系：
$$
\begin{aligned} 
\gamma_i&=\frac{\hat{\gamma}_i}{||w||}\\ 
\gamma&=\frac{\hat{\gamma}}{||w||}\\ 
\end{aligned}
$$


如果 ||w||=1  ，那么函数间隔和几何间隔相等。如果超平面参数 w 和 b 成比例地改变（超平面没有改变），函数间隔也按此比例改变，而几何间隔不变。

考虑几何间隔 $\gamma$ 和函数间隔 $\hat{\gamma}$ 的关系式（$\gamma=\frac{\hat{\gamma}}{||w||}$），可将这个问题改写为
$$
\begin{aligned} &\mathop{\text{max}}_{w,b}\quad \frac{\hat{\gamma}}{||w||}\\ &\text{s.t.}\quad y_i\left(w\cdot x_i+b\right)\geqslant \hat{\gamma},\ i=1,2,...,N\\ \end{aligned}
$$


函数间隔 $\hat{\gamma}$ 的取值并不影响最优化问题的解。事实上，假设将 w 和 b 按比例改变为 $\lambda w$ 和$\lambda b$ ，这时函数间隔为λ$\hat{\gamma}$。函数间隔的这一改变对上面最优化问题的不等式约束没有影响，对目标函数的优化也没有影响，也就是说，它产生一个等价的最优化问题。这样，就可以取函数间隔$\hat{\gamma}=1$。

将 $\hat{\gamma}=1$ 带入上面的最优化问题，注意到最大化 $\frac{1}{||w||}$ 和最小化 $\frac{1}{2}||w||^2$ 是等价的，于是就得到下面的线性可分支持向量机学习的最优化问题
$$
\begin{aligned} 
&\mathop{\text{min}}_{w,b}\quad \frac{1}{2}||w||^2\\ 
&\text{s.t.}\quad y_i\left(w\cdot x_i+b\right)-1\geqslant 0 \, i=1,2,...,N\\ 
\end{aligned}
$$
然后采用 对偶优化+KTT 条件求解 $w,b$。

#### 线性支持向量机

线性可分子问题的支持向量机学习方法，对线性不可分训练数据是不适用的，因为这时上述方法中的不等式约束并不能成立。怎么才能将它扩展到线性不可分问题呢？这就需要修改硬间隔最大化，使其成为软间隔最大化。

假设给定一个特征空间上的训练数据集

$T=\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\}$

其中，$x_i\in X=R^n$ ，$y_i\in Y=\{-1,+1\}$ ，$i=1,2,...,N$ ，$x_i$ 为第 i  个特征向量，也称为实例，$y_i$ 为 $x_i$ 的类标记。再假设训练数据集不是线性可分的。通常情况是，训练数据中有一些离群点，将这些离群点除去后，剩下大部分的样本组成的集合是线性可分的。

线性不可分意味着某些样本点是不能满足线性可分中的函数间隔大于等于1的约束条件的。为了解决这个问题，可以对每个样本点$(x_i,y_i)$ 引进一个松弛变量 $\xi_i\geqslant 0$ ，使函数间隔加上松弛变量大于等于1。这样，约束条件变为

​		$y_i(w\cdot x_i+b)\geqslant1-\xi_i$ 

**$\xi_i$ 是数据点到其分隔边界的函数距离，而 $1-\xi_i$ 则就是数据点到分界面的函数距离了。原来要求的是数据点到分界面的函数距离要大于等于1，现在就放宽到了数据点到分界面函数距离大于等于$1-\xi_i$。这其实是对异常离群点的一种容忍。**

目标函数变成了现在的

 $\frac{1}{2}||w||^2+C\sum_{i=1}^N\xi_i$ 

这里，C>0 称为惩罚函数，一般由应用问题决定，C 值大时对误分类的惩罚更大，C 值小时对误分类的惩罚减小。最小化目标函数（上式）包含了**两层含义**：

- **使 $\frac{1}{2}||w||^2$ 尽可能小，即间隔尽量大；**

- **同时使误分类点的个数尽可能小，**

  **而 C 是调和两者的系数**。

有了上面的思路，可以和训练数据集线性可分时一样来考虑训练数据集不可分时的线性支持向量机学习问题。相应于硬间隔最大化，它称为**软间隔最大化**。

线性不可分的线性支持向量机的学习问题变成如下凸二次规划问题：
$$
\begin{aligned} 
&\mathop{\text{min}}_{w,b,\xi}\quad \frac{1}{2}||w||^2+C\sum_{i=1}^N\xi_i\\ &\text{s.t.}\ \ \quad y_i(w\cdot x_i+b)\geqslant 1-\xi_i,\ i=1,2,...,N\\ 
&\ \ \ \quad \quad \xi_i\geqslant 0,\ i=1,2,...,N\\ \end{aligned}
$$

#### 核函数和非线性支持向量机

用线性分类方法求解非线性分类问题分为两步：

- **首先使用一个变换将原空间的数据映射到新空间**
- **然后在新空间中用线性分类学习方法从训练数据中学习分类模型**

**核技巧**就属于这样的方法。

核技巧应用到支持向量机，其基本思想就是通过一个非线性变换将输入空间（欧式空间或离散集合）对应于一个特征空间（希尔伯特空间 H ），使得在输入空间 $R^n$ 中的**超曲面模型**对应于特征空间中的**超平面模型（支持向量机）**。这样，分类问题的学习任务通过在特征空间求解线性支持向量机就可以完成。

##### 核函数

设X 是输入空间，又设 H为特征空间（希尔伯特空间，**特征空间的维度一般比输入空间的维度大**）如果存在一个从 X 到 H 的映射

$\phi(x):X\rightarrow H$ 

使得对所有$x,z\in X$ ，函数 K(x,z) 满足条件

$K(x,z)=\phi(x)\cdot \phi(z)$ 

则称 $K(x,z)$ 为核函数，$\phi(x)$ 为映射函数，式中$\phi(x)·\phi(z)$ 为 $\phi(x)$和$\phi(z)$ 的**内积**。

核技巧的想法是，在学习与预测中只定义核函数 $K(x,z)$ ，而不显式地定义映射函数$\phi$。

为什么要用核函数？**其高维空间内积后的结果可等效为在低维空间的样本向量通过核函数直接求得。所以用核函数**。

通常，直接计算$K(x,z)$比较容易，而通过 $\phi(x)$ 和 $\phi(z)$ 计算 K(x,z) 并不容易。注意，**$\phi$是输入空间$R^n$到特征空间的映射，特征空间一般是高维的，甚至是无穷维的**。

前面已经得到线性支持向量机的分界线：

$\sum_{i=1}^N\alpha_i^*y_i<x_i\cdot x>+b^*=0$

如果我们已经求得$\alpha^*$和$b^*$，那么**分界线就只依赖于x 和$x_i$ 的矢量积形式**，这一点非常关键。很多时候我们需要从数据中挖掘新的特征来进行训练，而不是简单粗暴地用原始数据，比如我们从 x 中挖掘出新的特征$x^2$ ，那我们还需要再一步步重新推导 y 的表达式吗？只需要将 $<x_i, x>$ 换成 $<x_i^2, x^2>$ 即可，更一般的描述：

如果存在一种映射关系$\phi(x)$ ，将 x 映射到另一空间中，已知

(拉格朗日对偶求$\alpha$结果后：$min_{w,b}L(w,b,α)=−\frac{1}{2}=∑_{1}^{N}j=∑^{N}_{1}α_iα_jy_iy_j(x_i⋅x_j)+∑_{1}^{N}α_i$)

$y=\sum_{k=1}^m\alpha_iy^{(i)}<x^{(i)},x>+b$

，那么新空间中的

$y=\sum_{k=1}^m\alpha_iy^{(i)}<\phi(x^{(i)}),\phi(x)>+b$

$\phi(x)$可以将数据从低维映射到高维空间当中，为分类提供了新的视角。

至于为什么需要映射后的特征而不是最初的特征来参与计算，上面提到的（为了**更好地拟合**）是其中一个原因。

另外的一个重要原因是**样例可能存在线性不可分的情况，而将特征映射到高维空间后，往往就可分了**。

- 实际中，我们会经常遇到线性不可分的样例，此时，我们的常用做法是把样例特征映射到高维空间中去（如上文最开始的那幅图所示，映射到高维空间后，相关特征便被分开了，也就达到了分类的目的）；
- 但进一步，如果凡是遇到线性不可分的样例，一律映射到高维空间，那么这个维度大小是会高到可怕的（如上文中19维乃至无穷维的例子）。那咋办呢？
- 此时，核函数就隆重登场了，核函数的价值在于它虽然也是将特征进行从低维到高维的转换，但核函数绝就绝在它**事先在低维上进行计算，而将实质上的分类效果表现在了高维上**，也就如上文所说的避免了直接在高维空间中的复杂计算。
- 核函数有效性判定: $K_{ij}=K(x(i),x(j))$ 组成的矩阵半正定

##### 线性核

K(x,z)=x^TzK(x,z)=xTz

线性核，实际上就是原始空间中的内积。这个核存在的主要目的是使得“映射后空间中的问题”和“映射前空间中的问题”两者在形式上统一起来了(意思是说，咱们有的时候，写代码，或写公式的时候，只要写个模板或通用表达式，然后再代入不同的核，便可以了，于此，便在形式上统一了起来，不用再分别写一个线性的，和一个非线性的)。

##### 高斯核函数

高斯核函数会将原始空间映射到无穷维空间(泰勒展开)

$K(x,z)=\text{exp}\left( -\frac{||x-z||^2}{2\sigma^2} \right)$

如果x 和 z很相近（$||x-z||\approx 0∣$ ），那么核函数值为1，如果x 和z 相差很大（$||x-z||\gg 0∣$ ），那么核函数值约等于0。由于这个函数类似于高斯分布，因此称为**高斯核函数**，也叫做**径向基函数(Radial Basis Function 简称RBF)。**它能够把原始特征映射到无穷维。

如果 σ 选得很大的话，高次特征上的权重实际上衰减得非常快，所以实际上（数值上近似一下）相当于一个低维的子空间；反过来，如果 σ 选得很小，则可以将任意的数据映射为线性可分——当然，这并不一定是好事，因为随之而来的可能是非常严重的过拟合问题。

不过，总的来说，通过调控参数 σ，高斯核实际上具有相当高的灵活性，也是使用最广泛的核函数之一。

#### SMO

重复下面过程直到收敛

（1）选择两个拉格朗日乘子αi和αj；

（2）固定其他拉格朗日乘子αk(k不等于i和j)，只对αi和αj优化w(**α**);

（3）根据优化后的αi和αj，更新截距b的值；

SMO算法是一种启发式算法，其基本思路是：**如果所有变量的解都满足此最优化问题的KKT条件，那么这个最优化问题的解就得到了。因为KKT条件是该最优化问题的充分必要条件**。否则，选择两个变量，固定其他变量，针对这两个变量构建一个二次规划问题。这个二次规划问题关于这两个变量的解应该更接近原始二次规划问题的解，因为这会使得原始二次规划问题的目标函数值变得更小。重要的是，这时子问题可以通过解析方法求解，这样就可以大大提高整个算法的计算速度。子问题有两个变量，一个是违反KKT条件最严重的那一个，另一个由约束条件自动确定。

整个SMO算法包括两个部分：

- 求解两个变量二次规划的解析方法
- 选择变量的启发式方法

### 集成学习--概述

##### Bagging

Bagging就是“Bootstrap aggregating（有放回采样的集成）”的缩写。Bagging是集成学习的一种，可提高用于统计分类回归的机器学习算法的稳定性和精度，也可以减小方差，有助于防止过拟合。虽然Bagging常使用决策树（即随机森林），但是也可用于任何方法，如朴素贝叶斯等。Bagging是模型平均方法（model averaging approach）的特例。

Bagging具体做法：对训练集进行随机子抽样，对每个子训练集构建基模型，对所有的基模型的预测结果进行综合产生最后的预测结果。如果是**分类**算法，则用多数投票法确定最终类别，如果是**回归**算法，则将各个回归结果做算术平均作为最终的预测值。

Bagging能防止噪声影响，是因为它的样本是有放回采样，这样子一些特例就很可能不会被采集到，即使采集到，也因为投票而被否决。这样就从样本上防止了过拟合。

Bagging样本的权值是一样的，各分类器的权值也都相等（即一人一票）。

##### Booting

提升的含义就是**将容易找到的识别率不高的弱分类算法提升为识别率很高的强分类算法**。

Boosting是一种提高任意给定学习算法（弱分类算法）准确度的方法，这种方法通过构造一个**预测函数系列**，然后以一定的方式将他们**组合成一个预测函数**。

它是一种框架算法，训练过程为阶梯状，基模型按照次序进行训练（实际上可以做到并行处理），先给定一个初始训练数据，训练出第一个基模型，根据基模型的表现对样本进行调整，在之前基模型预测错误的样本上投入更多的关注，然后用调整后的样本训练下一个基模型，重复上述过程N次，将N个基模型进行加权结合，输出最后的结果。

在这n个基分类器中，每个单个的分类器的识别率不一定很高，但他们联合后的结果有很高的识别率，这样便提高了该弱分类算法的识别率。在产生单个的基分类器时可用相同的分类算法，也可用不同的分类算法，这些算法一般是不稳定的弱分类算法，如朴素贝叶斯，决策树(C4.5)，神经网络(BP)等。

常用的算法有GBDT，XGBOOST等。

**booting基本方法与思路**

对于分类问题,给定一个训练样本集，求比较粗糙的分类规则（弱分类器）要比求精确的分类规则（强分类器）容易的多。提升方法就是从弱学习算法出发，反复学习，得到一系列弱分类器（基本分类器），然后组合这些弱分类器，后成一个强分类器。大多数的提升方法都是改变训练数据的概率分布（训练数据的权值分布），针对不同的训练数据分布，调用弱学习算法，学习一系列弱分类器。

这样，对提升方法来说，有两个问题需要回答：

- 每一轮如何改变训练数据的权值或概率分布
- 如何将弱分类器组合成一个强分类器

关于第一个问题，AdaBoost的做法是，提高那些被前一轮弱分类器错误分类的样本的权值，而降低那些被正确分类样本的权值。这样一来，那些没有得到正确分类的数据，由于其权值的加大，而受到后一轮的弱分类器的更大关注。于是，分类问题被一系列的弱分类器“分而治之”。

至于第二个问题，即弱分类器的组合，AdaBoost采取加权多数表决的方法。具体地，加大分类误差率小的弱分类器的权值，使其在表决中起较大作用减小分类误差率大的弱分类器的权值，使其在表决中起较小的作用。

通俗的说，AdaBoost的做法是：数据有权重，分类器也有权重。给数据分权重了，分错的话，权重会增加，该数据就越重要；同样也给臭皮匠（分类器）分等级了，有不同的地位，分类器准确率越高，权值就越大。

### Bagging : 决策树

**随机森林的构造过程：**

　　1. 假如有N个样本，则有放回的随机选择N个样本(每次随机选择一个样本，然后返回继续选择)。这选择好了的N个样本用来训练一个决策树，作为决策树根节点处的样本。

　　2. 当每个样本有M个属性时，在决策树的每个节点需要分裂时，随机从这M个属性中选取出m个属性，满足条件m << M。然后从这m个属性中采用某种策略（比如说信息增益）来选择1个属性作为该节点的分裂属性。

　　3. 决策树形成过程中每个节点都要按照步骤2来分裂（很容易理解，如果下一次该节点选出来的那一个属性是刚刚其父节点分裂时用过的属性，则该节点已经达到了叶子节点，无须继续分裂了）。一直到不能够再分裂为止。注意整个决策树形成过程中没有进行剪枝。

　　4. 按照步骤1~3建立大量的决策树，这样就构成了随机森林了。

在建立每一棵决策树的过程中，有两点需要注意采样与完全分裂。

首先是两个随机采样的过程，random forest对输入的数据要进行行、列的采样。对于行采样，采用有放回的方式，也就是在采样得到的样本集合中，可能有重复的样本。假设输入样本为N个，那么采样的样本也为N个。这样使得在训练的时候，每一棵树的输入样本都不是全部的样本，使得相对不容易出现over-fitting。然后进行列采样，从M个feature中，选择m个（m << M）。

之后就是对采样之后的数据使用完全分裂的方式建立出决策树，这样决策树的某一个叶子节点要么是无法继续分裂的，要么里面的所有样本的都是指向的同一个分类。一般很多的决策树算法都一个重要的步骤——剪枝，但是这里不这样干，由于之前的两个随机采样的过程保证了随机性，所以就算不剪枝，也不会出现over-fitting。

许多研究表明， 组合分类器比单一分类器的分类效果好，**随机森林（random forest）是一种利用多个分类树对数据进行判别与分类的方法，它在对数据进行分类的同时，还可以给出各个变量（基因）的重要性评分，评估各个变量在分类中所起的作用。**

随机森林算法得到的随机森林中的每一棵都是很弱的，但是大家组合起来就很厉害了。我觉得可以这样比喻随机森林算法：每一棵决策树就是一个精通于某一个窄领域的专家（因为我们从M个feature中选择m让每一棵决策树进行学习），这样在随机森林中就有了很多个精通不同领域的专家，对一个新的问题（新的输入数据），可以用不同的角度去看待它，最终由各个专家，投票得到结果。

**随机森林选择特征的方法**

**特征好坏衡量**

对每一颗决策树，选择相应的袋外数据（out of bag，$OOB$）计算袋外数据误差，记为 $errOOB1$.

所谓袋外数据是指，每次建立决策树时，通过重复抽样得到一个数据用于训练决策树，这时还有大约 $1/3$ 的数据没有被利用，没有参与决策树的建立。这部分数据可以用于对决策树的性能进行评估，计算模型的预测错误率，称为袋外数据误差。

随机对袋外数据$OOB$所有样本的特征$X$加入噪声干扰（可以随机改变样本在特征 $X$ 处的值），再次计算袋外数据误差，记为 $errOOB2$ 。
假设森林中有$N$棵树，则特征X的重要性 $=∑（errOOB2-errOOB1）/N$ 。

这个数值之所以能够说明特征的重要性是因为，如果加入随机噪声后，袋外数据准确率大幅度下降（即$errOOB2$上升），说明这个特征对于样本的预测结果有很大影响，进而说明重要程度比较高。

**特征选择**

在特征重要性的基础上，特征选择的步骤如下：

1.计算每个特征的重要性，并按降序排序

2.确定要剔除的比例，依据特征重要性剔除相应比例的特征，得到一个新的特征集

3.用新的特征集重复上述过程，直到剩下 $m$ 个特征（$m$为提前设定的值）

4.根据上述过程中得到的各个特征集和特征集对应的袋外误差率，选择袋外误差率最低的特征集。

### Adaboosting

**基本思想**

AdaBoost重复调用弱学习算法（多轮调用产生多个分类器），首轮调用弱学习算法时，按均匀分布从样本集中选取子集作为该次训练集，以后每轮对前一轮训练失败的样本，赋予较大的分布权值（$D_m$为第$m$轮各个样本在样本集中参与训练的权值），使其在这一轮训练出现的权值增加，即在后面的训练学习中集中对比较难训练的样本进行学习，从而得到$M$个弱的基分类器，$G_1, G_2, ... , G_m$，其中$G_m$有相应的权值$w_m$，并且其权值大小根据该分类器的效果而定。

最后的分类器由生成的多个分类器加权联合产生。

**算法流程**

输入：训练数据集 $$ T={ (x_1,y_1), (x_2,y_2), ... , (x_N,y_N) } $$ 其中，每个样本点由实例与标记组成。实例$x_i\in \mathcal{X}\subseteq R^n$，$y_i\in \mathcal{Y}={+1,-1}$；

弱学习算法；

输出：最终分类器$G(x)$

（1）初始化训练数据的权值分布 $$ D_1=(w_{11}, ... , w_{1i}, , ... ,w_{1N}),\quad w_{1i}=\frac{1}{N},\quad i=1,2,...,N $$ (每个训练样本在基本分类器的学习中作用相同，这一假设保证第一步能够在原始数据上学习基本分类器)

（2）对$m=1,2,...,M$

（a）使用具有权值分布$D_m$的训练数据学习，得到基本分类器  $$ G_m(x):\ \mathcal{X}\rightarrow { -1, +1 } $$ 

（b）计算$G_m(x)$在训练数据集上的分类误差率  $$ e_m=P(G_m(x_i)\neq y_i)=\sum_{i=1}^Nw_{mi}I(G_m(x_i)\neq y_i) $$ 

（c）计算$G_m(x)$的系数 $$ \alpha_m=\frac{1}{2}\text{ln}\frac{1-e_m}{e_m} $$ (**分类误差率越小的基本分类器在最终分类器中的作用越大**)

（d）更新训练数据集的权值分布
$$
\begin{aligned} 
D_{m+1}&=(w_{m+1,1},...,w_{m+1,i},...,w_{m+1,N})\\
w_{m+1,i}&=\frac{w_{mi}}{Z_m}\text{exp}(-\alpha_my_iG_m(x_i)),\quad i=1,2,...,N
\end{aligned} 
$$
 由此，使得误差越大，权重就越大。这里，$Z_m$是规范化因子 $$ Z_m=\sum_{i=1}^Nw_{mi}\text{exp}(-\alpha_my_iG_m(x_i)) $$ , 使$D_{m+1}$成为一个概率分布。

(由此可知，被基本分类器$G_m(x)$误分类的样本的权值得以扩大，而被正确分类的样本的权值却得以缩小。两相比较，误分类的样本的权值被放大了 $$ e^{2\alpha_m}=\frac{1-e_m}{e_m} $$ 倍。因此，误分类样本在下一轮学习中起到更大的作用。**不改变所给的训练数据，而不断改变训练数据权值的分布，使得训练数据在基本分类器的学习中起不同的作用，这是AdaBoost的一个特点**。)

（3）构建基本分类器的线性组合 $$ f(x)=\sum_{m=1}^M\alpha_mG_m(x) $$ 得到最终分类器 $$ G(x)=\text{sign}(f(x))=\text{sign}\left( \sum_{m=1}^M\alpha_mG_m(x) \right) $$(**利用基本分类器的线性组合构建最终分类器是AdaBoost的另一个特点**)



**AdaBoost的训练误差界**

AdaBoost算法最终分类器的训练误差界为 $$ \frac{1}{N}\sum_{i=1}^NI(G(x_i)\neq y_i)\leqslant\frac{1}{N}\sum_i\text{exp}(-y_if(x_i))=\prod_mZ_m $$ 这里，$G(x)$，$f(x)$和$Z_m$分别由上面已经给出。

**证明**：当$G(x)\neq y_i$时，$y_if(x_i)<0$，因而$\text{exp}(-y_if(x_i))\geqslant 1$。由此直接推导出前半部分。

后半部分的推导要用到$Z_m$的定义式及其上式的变形： $$ w_{mi}\text{exp}(-\alpha_my_iG_m(x_i))=Z_mw_{m+1,i} $$ 现推导如下： 
$$
\begin{aligned} 
&\frac{1}{N}\sum_i\text{exp}(-y_if(x_i))\\
=&\frac{1}{N}\sum_i\text{exp}\left(-\sum_{m=1}^M\alpha_my_iG_m(x_i)\right)\\ =&\sum_iw_{1i}\prod_{m=1}^M\text{exp}\left(-\alpha_my_iG_m(x_i)\right)\\ =&Z_1\sum_iw_{2i}\prod_{m=2}^M\text{exp}\left(-\alpha_my_iG_m(x_i)\right)\\ =&Z_1Z_2\sum_iw_{3i}\prod_{m=3}^M\text{exp}\left(-\alpha_my_iG_m(x_i)\right)\\
=&Z_1Z_2...Z_{M-1}\sum_iw_{Mi}\text{exp}\left(-\alpha_My_iG_M(x_i)\right)\\ =&\prod_{m=1}^MZ_m\ \end{aligned}
$$


这一定理说明，可以在每一轮选取适当的$G_m$使得$Z_m$最小，从而使训练误差下降最快。

### GBDT

GBDT主要由三个概念组成：Regression Decistion Tree（即DT)，Gradient Boosting（即GB)，Shrinkage。

**残差方式**

#### DT：回归树 RegressionDecisionTree

GBDT的核心在于累加所有树的结果作为最终结果，GBDT中的树都是回归树，不是分类树。

回归树在每个节点（不一定是叶子节点）都会得一个预测值，以年龄为例，该预测值等于属于这个节点的所有人年龄的平均值。分枝时穷举每一个feature的每个阈值找最好的分割点，但衡量最好的标准不再是最大熵，而是最小化均方差，即`(每个人的年龄-预测年龄)^2的总和` / `N`。

#### GB GradientBoosting

**GBDT的核心就在于，每一棵树学的是之前所有树结论和的残差**，这个残差就是一个加预测值后能得真实值的累加量，这其实就是平方误差的一阶导数。

**哪里体现了Gradient呢**？其实回到第一棵树结束时想一想，无论此时的cost function是什么，是均方差还是均差，只要它以误差作为衡量标准，残差向量都是它的全局最优方向，这就是Gradient。

回归问题提升树使用以下前向分步算法：
$$
\begin{aligned} 
&f_0(x)=0\\ 
&f_m(x)=f_{m-1}(x)+T(x;\Theta_m),\quad m=1,2,...,M\\ &f_M(x)=\sum_{m=1}^MT(x;\Theta_m)\\ \end{aligned}
$$


在前向分步算法的第 m 步，给定当前模型$f_{m-1}(x)$，需求解

$\hat{\Theta}_m=\text{arg }\mathop{\text{min}}_{\Theta_m}\sum_{i=1}^NL(y_i,f_{m-1}(x_i)+T(x_i;\Theta_m))$

得到$\hat{\Theta}_m$，即第 m 颗决策树的参数。

当采用平方误差损失函数时，

$L(y,f(x))=(y-f(x))^2$

其损失变为：
$$
\begin{aligned} 
&L(y,f_{m-1}(x)+T(x;\Theta_m))\\ 
=&[y-f_{m-1}(x)-T(x;\Theta_m)]^2\\ 
=&[r-T(x;\Theta_m)]^2 \end{aligned}
$$


这里，$r=y-f_{m-1}(x)$ 是当前模型拟合数据的残差。

为了使损失函数 $L$ 的值最小，对 $L$ 关于其中唯一的未知变量 $T(x; \Theta_m)$ 求偏导（$f_{m-1}(x)$已经是已知的定值了），并令其等于0，即可得使得损失函数LL最小的回归树 $T(x; \Theta_m)$ 。具体步骤如下：
$$
\begin{aligned} 
&\frac{\partial L(y,f_{m-1}(x)+T(x;\Theta_m))}{\partial T(x;\Theta)}\\ 
=&\frac{\partial [r-T(x;\Theta_m)]^2}{\partial T(x;\Theta)}\\ 
=&2[T(x;\Theta_m)-r]\\ 
=&0 \end{aligned}
$$


可得$T(x;\Theta_m)=r$ 。所以，对于回归问题的梯度提升算法来说，**只需要简单地拟合当前模型的残差**。这样，算法是相当简单的。

#### Shrinkage

每次走一小步逐渐逼近结果的效果，要比每次迈一大步很快逼近结果的方式更容易避免过拟合。即它不完全信任每一个棵残差树，它认为每棵树只学到了真理的一小部分，累加的时候只累加一小部分，通过多学几棵树弥补不足。用方程来看更清晰，即

没用Shrinkage时：（ $y_i$ 表示第 $i$ 棵树上 y 的预测值，$y_{(1-i)}$ 表示前 i 棵树 y 的综合预测值）

$y_{(i+1)}=\text{残差}(y_1\sim y_i)$

其中： $\text{残差}(y_1\sim y_i) = y_{\text{真实值}} - y_{(1\sim i)}$

$y_{(1\sim i)} = \sum(y_1, ..., y_i)$

Shrinkage不改变第一个方程，只把第二个方程改为：

$y_{(1\sim i)} = y_{(1\sim i-1)} + \text{step} \times y_i$

即Shrinkage仍然以残差作为学习目标，但对于残差学习出来的结果，只累加一小部分（step x 残差）逐步逼近目标，step一般都比较小，如0.01~0.001（注意该step非gradient的step），导致各个树的残差是渐变的而不是陡变的。直觉上这也很好理解，不像直接用残差一步修复误差，而是只修复一点点，其实就是把大步切成了很多小步。

**本质上，Shrinkage为每棵树设置了一个weight，累加时要乘以这个weight，但和Gradient并没有关系。**

**梯度提升算法**

**梯度提升算法：**

输入：训练数据集$T= \{ (x_1,y_1), (x_2,y_2), ... , (x_N,y_N) \}, x_i\in X\subseteq R^n，y_i\in Y\subseteq R$；

输出：回归树$\hat{f}(x)$。

**（1）**初始化

$f_0(x)=\text{arg }\mathop{\text{min}}_c\sum_{i=1}^NL(y_i,c)$

**（2）**对m=1,2,...,M

（a）对i=1,2,...,N，计算

$r_{mi}=-\left[ \frac{\partial L(y,f(x_i))}{\partial f(x_i)} \right]_{f(x)=f_{m-1}(x)}$,

计算损失函数的负梯度在当前模型的值，将它作为残差的估计。对于平方损失函数，它就是通常所说的残差；**对于一般损失函数（二阶导及以上不为零），它就是残差的近似值（泰勒展开，只取一阶导近似）**

（b）**对$r_{mi}$拟合一个回归树**，得到第 m 棵树的叶子节点区域$R_{mj}$, $j=1,2,...,J$

（c）对$j=1,2,...,J$，计算

$c_{mj}=\text{arg }\mathop{\text{min}}_c\sum_{x_i\in R_{mj}}$

利用线性搜索估计叶节点区域的值，使损失函数极小化

（d）更新

$f_m=f_{m-1}(x)+\sum_{j=1}^Jc_{mj}I(x\in R_{mj})$

更新回归树

**（3）**得到回归树

$\hat{f}(x)=f_M(x)=\sum_{m=1}^M\sum_{j=1}^Jc_{mj}I(x\in R_{mj})$

多分类与二分类问题都是采用特殊的 loss 函数达成的。

### XGBoost

![1.13.png](https://github.com/H-shw/Transformer_etc./blob/master/notes/AI%20note/pics/1.13.png?raw=true)

https://zhuanlan.zhihu.com/p/162001079



