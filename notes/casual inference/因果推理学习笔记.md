# 因果推理学习笔记

[toc]

## 知识栏

##### 因果关系之梯

在这本书中，Pearl将因果关系分为三个层次（他称之为“因果关系之梯”）。

自底到顶分别是：**关联**、**干预**、**反事实推理**。

* 最底层的是关联（Association），也就是我们通常意义下所认识的深度学习在做的事情，通过观察到的数据找出变量之间的关联性。这无法得出事件互相影响的方向，只知道两者相关，比如我们知道事件A发生时，事件B也发生，但我们并不能挖掘出，是不是因为事件A的发生导致了事件B的发生。观察层。
* 第二层级是干预（Intervention），也就是我们希望知道，当我们改变事件A时，事件B是否会跟着随之改变。行动层。
* 最高层级是反事实（Conterfactuals），也可以理解为“执果索因”，也就是我们希望知道，如果我们想让事件B发生某种变化时，我们能否通过改变事件A来实现。想象层。

举例说明，

**一个国家消耗的巧克力越多，该国人均产生的诺贝尔奖得主便越多**

* **关联**。我们仅仅得知这两者之间相关。为了探寻两者之间是否有因果关系，我们可以进行干预和反事实推理。
* **干预**。我们可以提问：如果给诺贝尔获得数量较少的国家的国民吃更多的巧克力，那么这个国家能有更多的诺贝尔奖获得者吗？这便是第二层级“干预”。很显然，答案是否定的。
* **反事实推理**。如果那些诺贝尔奖获得数量较多的国家的人没有吃那么多巧克力，他们还能获得那么多诺贝尔奖吗？

##### 有向无环图-DAG 与 贝叶斯网络

![1.1.png](https://github.com/H-shw/Transformer_etc./blob/master/notes/casual%20inference/pics/1.1.png?raw=true)



公式计算：
$$
P(x) = \prod^{n}_{i=1}p(x_i|\pi_{i})
$$
贝叶斯公式：
$$
P(A|B)=\frac{P(B|A)P(A)}{P(B)}
$$
可以用贝叶斯公式计算反向的关系。

贝叶斯网络的结构和参数可能并不知道。通过经验人为指定是一种方式，但并不一定准确。

实际效果并不好，特别是贝叶斯网络的结构，因为箭头的方向总容易学习错，**这根本原因还是贝叶斯网络并没有真正解决因果的问题，所以箭头的方向是假的因果方向，学习的效果总不对也是必然的**。

贝叶斯网络仍然没有因果的关系，说到底，贝叶斯网络也只是一张“**巨大的概率表的简洁形式**”。但贝叶斯网络所使用的有向无环图，仍然是因果图的重要组成部分。同时，贝叶斯网络中的概率公式也适用于因果图。



![1.2.png](https://github.com/H-shw/Transformer_etc./blob/master/notes/casual%20inference/pics/1.2.png?raw=true)

三种路径结构：**链式**（chain）、**叉式**（fork）、**反叉式/对撞**（inverted fork/collider）。

节点之间是有相关性的呢？如果两个节点分别位于路径的两端，那么如果：

- 有信息流向这两个节点
- 或者有信息从一个节点流向另一个节点

那么这两个节点就是相关的。

**如果一条从** $A$到 $B$ 的路径中出现了对撞接合，那么 $A$ **和** $B$ **就不可能是相关的**。

##### 概念：混杂

抽烟的人容易导致肺癌，抽烟的人也容易出现黄手指。

因为抽烟这个“**共因**”，“黄手指”和“肺癌”产生了关联，我们不难发现，手指黄的人很多都容易患肺癌。但是我们不能说，黄手指会导致肺癌，它俩并没有因果关系。

这个“**共因**”也被称之为“**混杂因子**”（confounder）。在这个例子中，“抽烟”就是“黄手指”和“肺癌”的混杂因子，它让“黄手指”和“肺癌”出现了一种“**伪相关**”，这种伪相关也被称为“**偏倚**”（bias）。

![1.3.png](https://github.com/H-shw/Transformer_etc./blob/master/notes/casual%20inference/pics/1.3.png?raw=true)

是否理解为：叉式的结构指向的两个部分就是共因？

**因果推理的一大目标就是尽量消除混杂带来的偏倚（也就是那些非因果的关联关系），找出真正的因果关系**

![1z.2.png](https://github.com/H-shw/Transformer_etc./blob/master/notes/casual%20inference/pics/1.2.png?raw=true)

●对于链式接合和叉式接合，通过“以中间变量 $B$ 为条件” (conditioning on variable B)，也即给定 $B$ 的值，比如指定 $B=1$ 或者指定 $B=0$ ，那么 $A$ 和 $C$ 之间路径被阻断(blocking) 。

●对于对撞接合,通过“以中间变量 $B$ 为条件"，$A$ 和 $C$ 之间原本被阻断的路径反而被打开，即 $A$ 和 $C$ 之间产生了相关性。

**当以 $B$ 为条件时(给B赋值)，关于 $A$ 的信息便不能让我们更多的关于 $C$ 的信息**

##### d-分离法则：

1. 如果一条路径中不以任何一个节点为条件，当且仅当该条路径中有两条箭头在某个变量处对撞时，则该条路径被阻断（该变量称为这条路径的对撞子）。
2. 如果一条路径包含一个非对撞子（noncollider），当以它为条件时，这条路径被阻断。以上图来看，即对于链式和叉式，以B为条件，切换 A , C 之间的联系。
3. 当以一个对撞子为条件时，该路径不会被阻断。即对于对撞式，以B为条件，A , C 之间反而会建立起来。
4. 当以一个对撞子的子孙为条件时，该路径也不会被阻断。

**后门路径**：变量 $A$ 和 $Y$ 之间的后门路径就是连接 $A$ 和 $Y$ 但箭头不从变量 $A$ 出发的路径。从变量 $A$ 到 $L$ 再到 $Y$ 的路径，如 $A←L→Y$ ，就是 $A$ 和 $Y$ 之间的后门路径 (backdoor path)。

**前门路径：** 连接 $A$ 和 $Y$ 但箭头且从变量 $A$ 出发的路径。 $A →B→ Y$ 就是前门路径( frontdoor path)。

**后门准则**：有足够的数据能够将所有 $A$ 和 $Y$ 之间的后门路径全部阻断 , 就可以识别 $A $ 和 $Y$ 之间的因果关系。

**混杂(confounding)** : 因果变量之间的共因。叉子的两端。

**混杂因子(confounder)**： 能够阻断因果变量之间所有后门路径的变量(可能混杂因子不止一个)。

混杂因子定义与判断方法:
1. [**从结构角度定义**] ： 如果以某个变量 $L$ 为条件使得变量 $A$ 和 $Y$ 之间的相关性发生了更改
(即原来相关变为不相关、原来不相关变为相关)，那么该变量 $L$ 为 $A$ 和 $Y$ 之间的混杂因子。
2. [**从传统角度定义**]：当变量 $L$ 满足以下三个条件时，$L$ 便是 $A$ 和 $Y$ 之间的混杂因子:


  * $L$ 与 $A$ 相关
  * 当以 $A$ 为条件时， $L$ 与 $Y$ 相关
  * $L$ 不在 $A$ 到 $Y$ 的因果关系路径中

要注意的是，结构角度的定义并不一定得到正确的判断， 很多情况下会带来选择偏倚等错误判断,所以两个角度结合起来判断更好。

判断步骤：

* 是否存在混杂。(有无后门路径)
* 结构角度观察是否是混杂因子。用 $d$ 分离法则，判断以其为条件能不能阻隔后门路径。
* 从传统角度的三个步骤看是否是混杂因子。

##### 结构因果模型

**结构因果模型** :结构因果模型包含两个变量集合 $U$ 和 $V$ ,以及一组函数$f$ , 该函数对变量集 $V$ 中的每一个变量进行赋值。

**更加正式的定义**:变量 $X$ 是变量 $Y$ 的直接原因(direct cause)，如果 $X $ 出现在对 $Y$ 进行赋值的函数中。如果，$X$ 是 $Y$ 的直接原因，或者是 $Y$ 的任何一个原因的原因，那么 $X$ 就是 $Y$ 的原因 (cause) 。

集合 $U$ 中的变量被称为**外生变量**( exogenous variables)，意思是这些变量是在模型外部存在的，我们不关心它们的因是什么。

集合 $V$ 中的变量被称为**内生变量**( endogenous variables)。模型中的每一个内生变量都是至少一个外生变量的后代。外生变量不能是其他变量的后代，特别是不能是内生变量的后代，它们没有祖先，在图中外生变量就是根节点。

如果我们知道每一个外生变量的值， 那么利用 $f$ 中的函数,我们就可以完全确定每一个内生变量的值。
$$
U = {X,Y}\\
V = {Z}\\
F = {f_z}\\
f_z : Z = 2X+3Y
$$
![1.4.png](https://github.com/H-shw/Transformer_etc./blob/master/notes/casual%20inference/pics/1.4.png?raw=true)

##### 干预与以变量为条件的区别

当我们在模型中对变量进行干预时，我们将固定这个变量的值。

其他变量的值也随之改变。当我们以一个变量为条件时，我们什么也不会改变;我们只是将关注的范围缩小到样本的子集，选取其中我们感兴趣的变量的值。

因此，以变量为条件改变的是我们看世界的角度，而干预则改变了世界本身。

**当我们进行干预以确定一个变量的值时，我们就限制了该变量随其他自然变量而变化的自然趋势。**

在图模型中，**干预的操作将删除所有指向该变量的边**。

与以某个变量为条件不同,干预一个变量会导致一种完全不同的相关性关系,以某个变量为条件可以完全从数据中获得，但干预却会影响图模型结构的变化。

##### 辛普森悖论

辛普森医生发现了一种新药，这种新药可以降低心脏病发作的风险，于是他开始查找历史的实验数据。他注意到，如果男性患者服用了这种药，心脏病发作的风险反而变高了。然后他再转向女性患者，结果大吃一惊：女性患者服用这种药以后心脏病发作的风险也变高了。但是这种药从数据上来说，对人类是有益的呀。为什么对女性有害、对男性有害，但对人类有益？

原因：$A/B>a/b,C/D>c/d,不能保证(A+C)/(B+D)>(a+c)/(b+d)$

![1.5.png](https://github.com/H-shw/Transformer_etc./blob/master/notes/casual%20inference/pics/1.5.png?raw=true)

性别在这里是一种混杂因子。

计算真正的影响应该是:
$$
P(Y=1|do(X=1))-P(Y=1|do(X=0))
$$
通过 $do$ 干预 , 我们的因果图就变为了

![1.6.png](https://github.com/H-shw/Transformer_etc./blob/master/notes/casual%20inference/pics/1.6.png?raw=true)

我们消除掉了 $Z$ 对 $X$ 的影响。

因此：
$$
\begin{align*}
P(Y=y|do(X=x)) &= \sum_{z}P(Y=y|do(X=x),Z=z)P(Z=z|do(X=x))(全概率公式)\\
&= \sum_{z}P(Y=y|do(X=x),Z=z)P(Z=z)\\
&= \sum_{z}P(Y=y|X=x,Z=z)P(Z=z)
\end{align*}
$$
这也是**后门准则**的推导公式。

如果我们把 $Z$ 理解为 $X$ 的父节点集合，则

调整公式告诉我们，如果我们要知道两个变量间的因果关系，比如 $X$ 对 $Y$ 的因果关系,那么我们可以通过调整$X$的父节点(集)来进行。

但是很多时候我们并不能观测所有需要知道的父节点(集)。所以我们必须诉诸其他节点来分析因果关系。后门准则就是其中一种重要的方法。

##### 后门调整

**后门准则的标准定义**: 给定一个有向无环图$G$，以及 $G$ 中的一对有序变量 $X$ 和 $Y$ ,如果一组变量 $Z$ 中的节点都不是 $X$ 的后代节点,并且以 $Z$ 为条件会阻断所有 $X$ 和 $Y$ 之间的后门路径，那么变量 $Z$ 满足关于 $(X,Y)$ 的后门准则。
进一步的，引出后门调整公式。如果变量$Z$满足关于$(X,Y)$的后门准则，那么 $X$ 对 $Y$ 的因果关系可以写作:
$$
\begin{align*}
P(Y=y|do(X=x)) &=  \sum_{z}P(Y=y|X=x,Z=z)P(Z=z)
\end{align*}
$$
![1.7.png](https://github.com/H-shw/Transformer_etc./blob/master/notes/casual%20inference/pics/1.7.png?raw=true)

如果我们不能观察 $Z$ , 可以用 $W$ 代替，也可以切断后门路径。

**一个奇怪但可能有用的例子**

![1.8.png](https://github.com/H-shw/Transformer_etc./blob/master/notes/casual%20inference/pics/1.8.png?raw=true)

$X$ 与 $Y$ 之间的因果关系不存在混杂, $X$ 与 $Y$ 之间也没有后门路径(注意 $X→W←Z←T→Y$ 不是后门路径，因为箭头方向是 $X$ 到 $W$ ，而不是 $W$ 到 $X$ )。所以实际上,对 $X$ 进行干预的结果就等于以$X$为条件的结果，即$P(y|do(x))= P(y|x)$。但$W$是一个对撞子,如果对$W$进行调整,会打开这条路径。

但是假如，我们还就真需要以 $W$ 为条件怎么办呢?比如说我们就希望知道当 $W= w$ 时，$X$
与 $Y$ 之间的因果关系。这时候我们要做的就只能是换一个变量来进行调整。我们可以对 $T$ 来进
行调整。根据调整公式:

$P(Y = y|do(X=x),W=w)= > P(Y =y|X=x,W =w,T=t)P(T=t|X=x,W= w)$

特别注意以上公式等号右边，$T$ 的条件概率也加上了$X$，这是因为以 $W$ 这个对撞子为条件，$T$ 和 $X$ 就不再是独立的了。

##### 前门调整

以有关吸烟与肺癌关系为例。遗憾的是，我们无法收集吸烟基因$U$的数据，所以我们无法使用后门准则来阻断后门路径 $X←U→Y$ 。

在这种情况下，我们可以引入前门准则:首先，我们观测“吸烟"对“焦油沉积”的平均因果效应;

然后，我们观测“焦油沉积”对“癌症”的平均因果效应;

最后我们将两者联立起来求出“吸烟”对“癌症”的因果效应。

![1.10.png](https://github.com/H-shw/Transformer_etc./blob/master/notes/casual%20inference/pics/1.10.png?raw=true)

首先，X对Z的因果效应是直接可以通过数据得到的， 没有混杂， 没有后门，也不需要用后门
路径，所以直接可以得到
$$
P(Z= z|do(X =x))= P(Z=z|X= x)
$$

接下来，$Z$对$Y$的因果效应,两者存在一个共因$U$，因此存在混杂，可以用后门路径调整,但由于$U$是未观测的变量,所以我们对$X$进行调整，即以X为条件,来阻断$Z←X←U→Y$，根据后门调整公式可得:
$$
P(Y = y)do(Z= z))=> P(Y=y|Z= z,X= x)P(X = x)
$$

符号

$G_{\overline x}$ :移除G中所有指向X的边，即X没有parent

$G_{\underline x}$ :移除G中所有被X指向的边，即X没有descendent

$G_{\overline {Z(W)}}$ :移除Z指向W的所有边，即Z中没有W的parent



##### do-calculus 的三条公理

$$
\begin{align*}
&公理1：增添或删除观察\\
    &\qquad P(y|do(x),z,w)=P(y|do(x),w)\qquad if(Y与Z无关|X,W)_{G_{\overline X}}\\
&公理2：干预与观察交换\\
&\qquad P(y|do(x),do(z),w)=P(y|do(x),z,w)\qquad if(Y与Z无关|X,W)_{G_{\overline X \underline Z}}\\
&公理3：增添或删除干预\\
&\qquad P(y|do(x),do(z),w)=P(y|do(x),w)\qquad if(Y与Z无关|X,W)_{G_{\overline X,\overline {Z(W)}}}\\
\end{align*}
$$



##### 推导前门调整


$$
\begin{align*}
P(Y = y|do(X=x))&= \sum_{z} P(Y = y|do(X=x),Z= z)P(Z = z|do(X = x))\\
&//step\,\,1:后门准则\\
&=  \sum_{z} P(Y = y|do(X = x),do(Z = z))P(Z = z|do(X = x))\\
&//step\,\,2:公理二。干预 \,Z,不改变效果\\
&=\sum_{z} P(Y = y|do(X = x),do(Z= z))P(Z=z|X= x)\\
&//step\,\,3:公理二。不改变效果\\
&=\sum_{z} P(Y= y|do(Z= z))P(Z=z|X=x)\\
&//step\,\,4:公理三。干预了Z,切断了X对Y的影响\\
&=\sum_{z} P(Y = y|do(Z=z),X =x')P(X =x'|do(Z=z))P(Z= z|X=x)\\
&//step\,\,5:全概率公式，展开x\\
&=\sum_{x'}\sum_{z} P(Y=y|Z=z,X=x')P(X=x'| do( Z= z))P(Z=z|X=x)\\
&//step\,\,6:公理二。去掉Z的do\\
&=\sum_{z} P(Y=y|Z=z,X=x')P(X=x')P(Z=z|X=x)\\
&//step\,\,7:公理三。X与Z无关\\
\end{align*}
$$



最终我们可以得到：
$$
P(Y=y|do(X=x))=\sum_{z}P(Z=z|X=x)\sum_{x'}P(Y=y|X=x',Z=z)P(X=x')
$$

最后，我们总结前门准则和前面调整的定义如下:

如果变量 $Z$ 满足:

1. $Z$ 阻断了所有 $X$ 到 $Y$ 之间的路径;

2. $X$ 到 $Z$ 之间没有未阻断的路径;

3. $Z$ 到 $Y$ 之间所有的后门路径都被X阻断,

那么我们称Z满足有序变量$(X,Y)$的前门准则。

更进一步地， 前门调整的概念是：如果Z满足关于有序变量$(X,Y)$的前门准则，并且如果$P(x,z)>0$,那么X对于$Y$的因果关系就可以被如下的公式估计:
$$
P(y|do(x))= \sum_{z} P(z|x)\sum_{x'} P(y|x',z)P(x')
$$



##### 逆概率加权

$$
\begin{align*}
P(Y=y|do(X=x))&=\sum_{z}P(Y=y|X=x,Z=z)P(Z=z)\\
&=\sum_{z}\frac{P(Y=y|X=x,Z=z)P(Z=z)P(X=x|Z=z)}{P(X=x|Z=z)}\\
&=\sum_{z}\frac{P(Y=y,X=x,Z=z)}{P(X=x|Z=z)}\\
\end{align*}
$$



## 资源栏

因果博客 https://zhuanlan.zhihu.com/p/109729340

参考书籍：*CAUSAL INFERENCE IN STATISTICS A PRIMER* (https://zh.usa1lib.org/book/2664651/adcbf6) pdf版下载地址

do-calculus 的 3个公理:https://zhuanlan.zhihu.com/p/336128992

