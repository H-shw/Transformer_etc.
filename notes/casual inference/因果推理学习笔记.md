# 因果推理学习笔记

[toc]

## 知识栏

##### 因果关系之梯

在这本书中，Pearl将因果关系分为三个层次（他称之为“因果关系之梯”）。

自底到顶分别是：**关联**、**干预**、**反事实推理**。

* 最底层的是关联（Association），也就是我们通常意义下所认识的深度学习在做的事情，通过观察到的数据找出变量之间的关联性。这无法得出事件互相影响的方向，只知道两者相关，比如我们知道事件A发生时，事件B也发生，但我们并不能挖掘出，是不是因为事件A的发生导致了事件B的发生。观察层。
* 第二层级是干预（Intervention），也就是我们希望知道，当我们改变事件A时，事件B是否会跟着随之改变。行动层。
* 最高层级是反事实（Conterfactuals），也可以理解为“执果索因”，也就是我们希望知道，如果我们想让事件B发生某种变化时，我们能否通过改变事件A来实现。想象层。

举例说明，

**一个国家消耗的巧克力越多，该国人均产生的诺贝尔奖得主便越多**

* **关联**。我们仅仅得知这两者之间相关。为了探寻两者之间是否有因果关系，我们可以进行干预和反事实推理。
* **干预**。我们可以提问：如果给诺贝尔获得数量较少的国家的国民吃更多的巧克力，那么这个国家能有更多的诺贝尔奖获得者吗？这便是第二层级“干预”。很显然，答案是否定的。
* **反事实推理**。如果那些诺贝尔奖获得数量较多的国家的人没有吃那么多巧克力，他们还能获得那么多诺贝尔奖吗？

##### 有向无环图-DAG 与 贝叶斯网络

![1.1.png](https://github.com/H-shw/Transformer_etc./blob/master/notes/casual%20inference/pics/1.1.png?raw=true)



公式计算：
$$
P(x) = \prod^{n}_{i=1}p(x_i|\pi_{i})
$$
贝叶斯公式：
$$
P(A|B)=\frac{P(B|A)P(A)}{P(B)}
$$
可以用贝叶斯公式计算反向的关系。

贝叶斯网络的结构和参数可能并不知道。通过经验人为指定是一种方式，但并不一定准确。

实际效果并不好，特别是贝叶斯网络的结构，因为箭头的方向总容易学习错，**这根本原因还是贝叶斯网络并没有真正解决因果的问题，所以箭头的方向是假的因果方向，学习的效果总不对也是必然的**。

贝叶斯网络仍然没有因果的关系，说到底，贝叶斯网络也只是一张“**巨大的概率表的简洁形式**”。但贝叶斯网络所使用的有向无环图，仍然是因果图的重要组成部分。同时，贝叶斯网络中的概率公式也适用于因果图。



![1.2.png](https://github.com/H-shw/Transformer_etc./blob/master/notes/casual%20inference/pics/1.2.png?raw=true)

三种路径结构：**链式**（chain）、**叉式**（fork）、**反叉式/对撞**（inverted fork/collider）。

节点之间是有相关性的呢？如果两个节点分别位于路径的两端，那么如果：

- 有信息流向这两个节点
- 或者有信息从一个节点流向另一个节点

那么这两个节点就是相关的。

**如果一条从** $A$到 $B$ 的路径中出现了对撞接合，那么 $A$ **和** $B$ **就不可能是相关的**。

##### 概念：混杂

抽烟的人容易导致肺癌，抽烟的人也容易出现黄手指。

因为抽烟这个“**共因**”，“黄手指”和“肺癌”产生了关联，我们不难发现，手指黄的人很多都容易患肺癌。但是我们不能说，黄手指会导致肺癌，它俩并没有因果关系。

这个“**共因**”也被称之为“**混杂因子**”（confounder）。在这个例子中，“抽烟”就是“黄手指”和“肺癌”的混杂因子，它让“黄手指”和“肺癌”出现了一种“**伪相关**”，这种伪相关也被称为“**偏倚**”（bias）。

![1.3.png](https://github.com/H-shw/Transformer_etc./blob/master/notes/casual%20inference/pics/1.3.png?raw=true)

是否理解为：叉式的结构指向的两个部分就是共因？

**因果推理的一大目标就是尽量消除混杂带来的偏倚（也就是那些非因果的关联关系），找出真正的因果关系**

![1z.2.png](https://github.com/H-shw/Transformer_etc./blob/master/notes/casual%20inference/pics/1.2.png?raw=true)

●对于链式接合和叉式接合，通过“以中间变量 $B$ 为条件” (conditioning on variable B)，也即给定 $B$ 的值，比如指定 $B=1$ 或者指定 $B=0$ ，那么 $A$ 和 $C$ 之间路径被阻断(blocking) 。

●对于对撞接合,通过“以中间变量 $B$ 为条件"，$A$ 和 $C$ 之间原本被阻断的路径反而被打开，即 $A$ 和 $C$ 之间产生了相关性。

**当以 $B$ 为条件时(给B赋值)，关于 $A$ 的信息便不能让我们更多的关于 $C$ 的信息**

##### d-分离法则：

1. 如果一条路径中不以任何一个节点为条件，当且仅当该条路径中有两条箭头在某个变量处对撞时，则该条路径被阻断（该变量称为这条路径的对撞子）。
2. 如果一条路径包含一个非对撞子（noncollider），当以它为条件时，这条路径被阻断。以上图来看，即对于链式和叉式，以B为条件，切换 A , C 之间的联系。
3. 当以一个对撞子为条件时，该路径不会被阻断。即对于对撞式，以B为条件，A , C 之间反而会建立起来。
4. 当以一个对撞子的子孙为条件时，该路径也不会被阻断。

**后门路径**：变量 $A$ 和 $Y$ 之间的后门路径就是连接 $A$ 和 $Y$ 但箭头不从变量 $A$ 出发的路径。从变量 $A$ 到 $L$ 再到 $Y$ 的路径，如 $A←L→Y$ ，就是 $A$ 和 $Y$ 之间的后门路径 (backdoor path)。

**前门路径：** 连接 $A$ 和 $Y$ 但箭头且从变量 $A$ 出发的路径。 $A →B→ Y$ 就是前门路径( frontdoor path)。

**后门准则**：有足够的数据能够将所有 $A$ 和 $Y$ 之间的后门路径全部阻断 , 就可以识别 $A $ 和 $Y$ 之间的因果关系。

**混杂(confounding)** : 因果变量之间的共因。叉子的两端。

**混杂因子(confounder)**： 能够阻断因果变量之间所有后门路径的变量(可能混杂因子不止一个)。

混杂因子定义与判断方法:
1. [**从结构角度定义**] ： 如果以某个变量 $L$ 为条件使得变量 $A$ 和 $Y$ 之间的相关性发生了更改
(即原来相关变为不相关、原来不相关变为相关)，那么该变量 $L$ 为 $A$ 和 $Y$ 之间的混杂因子。
2. [**从传统角度定义**]：当变量 $L$ 满足以下三个条件时，$L$ 便是 $A$ 和 $Y$ 之间的混杂因子:


  * $L$ 与 $A$ 相关
  * 当以 $A$ 为条件时， $L$ 与 $Y$ 相关
  * $L$ 不在 $A$ 到 $Y$ 的因果关系路径中

要注意的是，结构角度的定义并不一定得到正确的判断， 很多情况下会带来选择偏倚等错误判断,所以两个角度结合起来判断更好。

判断步骤：

* 是否存在混杂。(有无后门路径)
* 结构角度观察是否是混杂因子。用 $d$ 分离法则，判断以其为条件能不能阻隔后门路径。
* 从传统角度的三个步骤看是否是混杂因子。

##### 结构因果模型

**结构因果模型** :结构因果模型包含两个变量集合 $U$ 和 $V$ ,以及一组函数$f$ , 该函数对变量集 $V$ 中的每一个变量进行赋值。

**更加正式的定义**:变量 $X$ 是变量 $Y$ 的直接原因(direct cause)，如果 $X $ 出现在对 $Y$ 进行赋值的函数中。如果，$X$ 是 $Y$ 的直接原因，或者是 $Y$ 的任何一个原因的原因，那么 $X$ 就是 $Y$ 的原因 (cause) 。

集合 $U$ 中的变量被称为**外生变量**( exogenous variables)，意思是这些变量是在模型外部存在的，我们不关心它们的因是什么。

集合 $V$ 中的变量被称为**内生变量**( endogenous variables)。模型中的每一个内生变量都是至少一个外生变量的后代。外生变量不能是其他变量的后代，特别是不能是内生变量的后代，它们没有祖先，在图中外生变量就是根节点。

如果我们知道每一个外生变量的值， 那么利用 $f$ 中的函数,我们就可以完全确定每一个内生变量的值。
$$
U = {X,Y}\\
V = {Z}\\
F = {f_z}\\
f_z : Z = 2X+3Y
$$
![1.4.png](https://github.com/H-shw/Transformer_etc./blob/master/notes/casual%20inference/pics/1.4.png?raw=true)

##### 干预与以变量为条件的区别

当我们在模型中对变量进行干预时，我们将固定这个变量的值。

其他变量的值也随之改变。当我们以一个变量为条件时，我们什么也不会改变;我们只是将关注的范围缩小到样本的子集，选取其中我们感兴趣的变量的值。

因此，以变量为条件改变的是我们看世界的角度，而干预则改变了世界本身。

**当我们进行干预以确定一个变量的值时，我们就限制了该变量随其他自然变量而变化的自然趋势。**

在图模型中，**干预的操作将删除所有指向该变量的边**。

与以某个变量为条件不同,干预一个变量会导致一种完全不同的相关性关系,以某个变量为条件可以完全从数据中获得，但干预却会影响图模型结构的变化。

##### 辛普森悖论

辛普森医生发现了一种新药，这种新药可以降低心脏病发作的风险，于是他开始查找历史的实验数据。他注意到，如果男性患者服用了这种药，心脏病发作的风险反而变高了。然后他再转向女性患者，结果大吃一惊：女性患者服用这种药以后心脏病发作的风险也变高了。但是这种药从数据上来说，对人类是有益的呀。为什么对女性有害、对男性有害，但对人类有益？

原因：$A/B>a/b,C/D>c/d,不能保证(A+C)/(B+D)>(a+c)/(b+d)$

![1.5.png](https://github.com/H-shw/Transformer_etc./blob/master/notes/casual%20inference/pics/1.5.png?raw=true)

性别在这里是一种混杂因子。

计算真正的影响应该是:
$$
P(Y=1|do(X=1))-P(Y=1|do(X=0))
$$
通过 $do$ 干预 , 我们的因果图就变为了

![1.6.png](https://github.com/H-shw/Transformer_etc./blob/master/notes/casual%20inference/pics/1.6.png?raw=true)

我们消除掉了 $Z$ 对 $X$ 的影响。

因此：
$$
\begin{align*}
P(Y=y|do(X=x)) &= \sum_{z}P(Y=y|do(X=x),Z=z)P(Z=z|do(X=x))(全概率公式)\\
&= \sum_{z}P(Y=y|do(X=x),Z=z)P(Z=z)\\
&= \sum_{z}P(Y=y|X=x,Z=z)P(Z=z)
\end{align*}
$$
这也是**后门准则**的推导公式。

如果我们把 $Z$ 理解为 $X$ 的父节点集合，则

调整公式告诉我们，如果我们要知道两个变量间的因果关系，比如 $X$ 对 $Y$ 的因果关系,那么我们可以通过调整$X$的父节点(集)来进行。

但是很多时候我们并不能观测所有需要知道的父节点(集)。所以我们必须诉诸其他节点来分析因果关系。后门准则就是其中一种重要的方法。

##### 后门调整

**后门准则的标准定义**: 给定一个有向无环图$G$，以及 $G$ 中的一对有序变量 $X$ 和 $Y$ ,如果一组变量 $Z$ 中的节点都不是 $X$ 的后代节点,并且以 $Z$ 为条件会阻断所有 $X$ 和 $Y$ 之间的后门路径，那么变量 $Z$ 满足关于 $(X,Y)$ 的后门准则。
进一步的，引出后门调整公式。如果变量$Z$满足关于$(X,Y)$的后门准则，那么 $X$ 对 $Y$ 的因果关系可以写作:
$$
\begin{align*}
P(Y=y|do(X=x)) &=  \sum_{z}P(Y=y|X=x,Z=z)P(Z=z)
\end{align*}
$$
![1.7.png](https://github.com/H-shw/Transformer_etc./blob/master/notes/casual%20inference/pics/1.7.png?raw=true)

如果我们不能观察 $Z$ , 可以用 $W$ 代替，也可以切断后门路径。

**一个奇怪但可能有用的例子**

![1.8.png](https://github.com/H-shw/Transformer_etc./blob/master/notes/casual%20inference/pics/1.8.png?raw=true)

$X$ 与 $Y$ 之间的因果关系不存在混杂, $X$ 与 $Y$ 之间也没有后门路径(注意 $X→W←Z←T→Y$ 不是后门路径，因为箭头方向是 $X$ 到 $W$ ，而不是 $W$ 到 $X$ )。所以实际上,对 $X$ 进行干预的结果就等于以$X$为条件的结果，即$P(y|do(x))= P(y|x)$。但$W$是一个对撞子,如果对$W$进行调整,会打开这条路径。

但是假如，我们还就真需要以 $W$ 为条件怎么办呢?比如说我们就希望知道当 $W= w$ 时，$X$
与 $Y$ 之间的因果关系。这时候我们要做的就只能是换一个变量来进行调整。我们可以对 $T$ 来进
行调整。根据调整公式:

$P(Y = y|do(X=x),W=w)= > P(Y =y|X=x,W =w,T=t)P(T=t|X=x,W= w)$

特别注意以上公式等号右边，$T$ 的条件概率也加上了$X$，这是因为以 $W$ 这个对撞子为条件，$T$ 和 $X$ 就不再是独立的了。

##### 前门调整

以有关吸烟与肺癌关系为例。遗憾的是，我们无法收集吸烟基因$U$的数据，所以我们无法使用后门准则来阻断后门路径 $X←U→Y$ 。

在这种情况下，我们可以引入前门准则:首先，我们观测“吸烟"对“焦油沉积”的平均因果效应;

然后，我们观测“焦油沉积”对“癌症”的平均因果效应;

最后我们将两者联立起来求出“吸烟”对“癌症”的因果效应。

![1.10.png](https://github.com/H-shw/Transformer_etc./blob/master/notes/casual%20inference/pics/1.10.png?raw=true)

首先，X对Z的因果效应是直接可以通过数据得到的， 没有混杂， 没有后门，也不需要用后门
路径，所以直接可以得到
$$
P(Z= z|do(X =x))= P(Z=z|X= x)
$$

接下来，$Z$对$Y$的因果效应,两者存在一个共因$U$，因此存在混杂，可以用后门路径调整,但由于$U$是未观测的变量,所以我们对$X$进行调整，即以X为条件,来阻断$Z←X←U→Y$，根据后门调整公式可得:
$$
P(Y = y)do(Z= z))=> P(Y=y|Z= z,X= x)P(X = x)
$$

符号

$G_{\overline x}$ :移除G中所有指向X的边，即X没有parent

$G_{\underline x}$ :移除G中所有被X指向的边，即X没有descendent

$G_{\overline {Z(W)}}$ :移除Z指向W的所有边，即Z中没有W的parent



##### do-calculus 的三条公理

$$
\begin{align*}
&公理1：增添或删除观察\\
    &\qquad P(y|do(x),z,w)=P(y|do(x),w)\qquad if(Y与Z无关|X,W)_{G_{\overline X}}\\
&公理2：干预与观察交换\\
&\qquad P(y|do(x),do(z),w)=P(y|do(x),z,w)\qquad if(Y与Z无关|X,W)_{G_{\overline X \underline Z}}\\
&公理3：增添或删除干预\\
&\qquad P(y|do(x),do(z),w)=P(y|do(x),w)\qquad if(Y与Z无关|X,W)_{G_{\overline X,\overline {Z(W)}}}\\
\end{align*}
$$



##### 推导前门调整


$$
\begin{align*}
P(Y = y|do(X=x))&= \sum_{z} P(Y = y|do(X=x),Z= z)P(Z = z|do(X = x))\\
&//step\,\,1:后门准则\\
&=  \sum_{z} P(Y = y|do(X = x),do(Z = z))P(Z = z|do(X = x))\\
&//step\,\,2:公理二。干预 \,Z,不改变效果\\
&=\sum_{z} P(Y = y|do(X = x),do(Z= z))P(Z=z|X= x)\\
&//step\,\,3:公理二。不改变效果\\
&=\sum_{z} P(Y= y|do(Z= z))P(Z=z|X=x)\\
&//step\,\,4:公理三。干预了Z,切断了X对Y的影响\\
&=\sum_{z} P(Y = y|do(Z=z),X =x')P(X =x'|do(Z=z))P(Z= z|X=x)\\
&//step\,\,5:全概率公式，展开x\\
&=\sum_{x'}\sum_{z} P(Y=y|Z=z,X=x')P(X=x'| do( Z= z))P(Z=z|X=x)\\
&//step\,\,6:公理二。去掉Z的do\\
&=\sum_{z} P(Y=y|Z=z,X=x')P(X=x')P(Z=z|X=x)\\
&//step\,\,7:公理三。X与Z无关\\
\end{align*}
$$



最终我们可以得到：
$$
P(Y=y|do(X=x))=\sum_{z}P(Z=z|X=x)\sum_{x'}P(Y=y|X=x',Z=z)P(X=x')
$$

最后，我们总结前门准则和前面调整的定义如下:

如果变量 $Z$ 满足:

1. $Z$ 阻断了所有 $X$ 到 $Y$ 之间的路径;

2. $X$ 到 $Z$ 之间没有未阻断的路径;

3. $Z$ 到 $Y$ 之间所有的后门路径都被X阻断,

那么我们称Z满足有序变量$(X,Y)$的前门准则。

更进一步地， 前门调整的概念是：如果Z满足关于有序变量$(X,Y)$的前门准则，并且如果$P(x,z)>0$,那么X对于$Y$的因果关系就可以被如下的公式估计:
$$
P(y|do(x))= \sum_{z} P(z|x)\sum_{x'} P(y|x',z)P(x')
$$



##### 逆概率加权

$$
\begin{align*}
P(Y=y|do(X=x))&=\sum_{z}P(Y=y|X=x,Z=z)P(Z=z)\\
&=\sum_{z}\frac{P(Y=y|X=x,Z=z)P(Z=z)P(X=x|Z=z)}{P(X=x|Z=z)}\\
&=\sum_{z}\frac{P(Y=y,X=x,Z=z)}{P(X=x|Z=z)}\\
\end{align*}
$$



##### 回归系数 与 路径系数

$$
E[Y|X_{1} = x_{1},X_{2} = x_{2}....,X_{n} = x_{n}]=r_{0} +r_{1}x_{1} + r_{2}x_{2} +...+ r_{n}x_{n}
$$



其中$r_1$ , $r_2$ ,..., $r_{n}$ 被称为回归系数(或者相关系数)。

回归系数是表示变量之间的统计特征，也就是我们站在因果关系之梯第一层级用观测数据归纳出
的，它只是对客观事实的描述，$y= r_{1}x十r_{2}y$ 不能说明$X$和$Z$是$Y$的因。

与回归系数不同，路径系数则反映的是变量之间的因果关系或者结构关系，是因果关系之梯第二层级的信息。比如我们定义 $Y=3X+U $ 这就说明 $X$ 和 $Y$ 之间有因果关系路径 $X→Y$ , 且路径系数为 $3$。**每一个路径系数都表示一条因果关系。**

考虑下图中的图模型。其中$a,b, c, d, e$分别标出了五条因果关系路径的路径系数。

事实上，这样，我们就将图的三个要素都凑齐了。(节点代表变量，边代表因果关系，权重代表路径系数，可以代表一条因果关系的决定程度？)



![1.11.png](https://github.com/H-shw/Transformer_etc./blob/master/notes/casual%20inference/pics/1.11.png?raw=true)

假设我们想要计算$Z$对$Y$的因果效应的总和。那么计算的方式就是将每一条因果路径上的因果
系数与对应变量相乘,然后对所有非后门路径求和。
$$
\begin{align*}
Y&=dZ+eW + U_{y}\\
&=dZ+e(bX+cZ)+U_{Y}+eU_{w}\\
&=(d+ec)Z+ebX+U_{Y}+eU_{w}
\end{align*}
$$


##### 计算两个变量之间的直接效应

![1.12.png](https://github.com/H-shw/Transformer_etc./blob/master/notes/casual%20inference/pics/1.12.png?raw=true)

比如计算 $X$ 与 $Y$ 的直接效应 $\alpha$ 。

方法如下:

1.移除$X$与$Y$之间的箭头(如果没有直接相连的箭头,那就说明 $a=0$ )。

2.得到的新图称为 $G_a$，如果 $G_a$ 中有一组变量 $Z$ 能够将 $X$ 和  $Y$ d分离 ,那么我们就可以求出 $Y$ 关于 $X$ 和 $Z$ 的回归模型。

如图2 (左)的有向无环图，我们去掉 X $\rightarrow$ Y 的箭头，得到右边的有向无环图,在右图中,W作为中间节点d分离了X和Y。因此我们建立Y关于X和W的回归模型:

$Y=r_{x}X+r_{w}W十∈$

其中 $r_x$ 就是 $X$ 对 $Y$ 的直接因果效应。然后我们只要观测出回归模型中这些变量的值就可以估计出参数的值了。



##### 工具变量

去掉箭头以后，没有变量能将 $X$ 和 $Y$ d分离，**且X到Y之间存在一个无法观察的变量(可能是混杂因子，是否相当于把Z视作上文不需要工具变量的X？)**, 可以引入工具变量

![1.13.png](https://github.com/H-shw/Transformer_etc./blob/master/notes/casual%20inference/pics/1.13.png?raw=true)

$X$ 和 $Y$ 之间只有一条路径 $a$，还有一个未观测的共因(虚线表示)。
此时，去掉$X$和$Y$之间的箭头后，无法找到能够$d$分离$X$和$Y$的变量(集)了。

此时应当找一个工具变量 $Z$ 来求出 $\alpha$.

如果一个变量在新的图 $G_a$ 中与 $Y$ 是d分离，但是与 $X$ 是d相连的，那么这个变量就可以被作为工具变量。

建立 $Y$ 关于 $Z、X$ 关于 $Z$ 的回归关系：$y=r_{1}z \, +∈、x=r_{2}z \,+∈$。
$$
β= r_2\\
aβ= r_1\\
\alpha = r_{1}/r_{2}
$$

##### 中介

![1.14.png](https://github.com/H-shw/Transformer_etc./blob/master/notes/casual%20inference/pics/1.14.png?raw=true)

上图中，我们认为 学历 $Z$ 是一个中介。

**要注意这与后门路径的不同，后门准则使用的场景是叉式的共因，中介是链式的，计算直接影响。**

首先，性别直接影响录取结果 ， 其次,性别通过学历这个中介变量来间接影响录取结果。

为了找到性别对录取结果的直接效应，我们需要以某种方式消除中介变量(此时就是混杂因子)的影
响，也即保持学历不变,然后衡量性别与录取结果之间的关系: 由于学历不变 , 录取结果上的任何变化都只能由性别决定。这是通过**以中介变量为条件**来实现的。

而对于右图，以中介变量为条件不能获得性别与录取结果直接的关系，因此应当干预 $Z$ ,切断 $X$ 或 $I$ 经由 $Z$ 的间接路径或后门路径。

**受控直接效应**（Controlled Directed Effect, CDE）

其计算方式为:
$$
\begin{align*}
CDE&= P(Y = y|do(X= x),do(Z= z))- P(Y = y|do(X = x), do(Z = z))\\
&//使用法则2,\,P(y|do(x),do(z),w)=P(y|do(x),z,w)\,\,\,if(Y与Z无关|X,W)_{G_{\overline X \underline Z}}\\
&= P(Y =y|X=x,do(Z=z))- P(Y =y|X= x',do(Z= z))\\
&//后门准则的应用\\
&= \sum_{i}[P(Y=y|X=x,Z=z,I=i) - P(Y =y|X =x',Z=z,I = i)]P(I =i)
\end{align*}
$$
当以下两个条件都满足时,以Z为中介变量，可以计算出变量$X$对变量$Y$的**CDE**:

1.存在一组变量集 $S_1$ 能够阻断 $Z \rightarrow Y$ 的所有后门路径 (去除**中介**的影响)。

2.当去掉指向 $Z$ 的所有箭头后，存在 变量集 $S_2$ 能够阻断 $X \rightarrow Y$ 的所有后门路径(去除**后门路径**的影响)。

##### 反事实（Counterfactual）

通过未发生的条件来推理可能的结果，就是反事实推理的问题。

我们用$M$表示结构因果模型，$F$ 表示 $M$ 中的函数集，$V$ 是 $M$ 中的变量集。$U=u$ 表示对某个外生变量的赋值。

**反事实的表述: $Y_{x}(u)=y$, 表示" 在 $U=u$ 的情形下，假如 $X=x$  , 则 $Y=y$ 。**

假如 $X=x$ 可以看作外部的干预，$do(X=x)$ 

假设一个结构因果模型M定义如下:
$$
X=aU\\
Y= bX+ U
$$
那么计算反事实 $Y_{x}(u)$ 就意味着在求$U= u$时,如果我们强制让$X =x$，$Y$应该等于多少。这个操作无疑也改变了X的来源。

所以新的结构因果模型$M_{x}$为
$$
X= x\\
Y= bX+U
$$
再代入 $U = u$ ， $Y_{x}(u) = bx+u$。

在原模型 $M$ 中的反事实 $Y_{x}(u)$ 等于修改过的模型 $M_x$ 中 $Y$ 的计算值:
$$
Y_{x}(u)= Y_{M_{x}}(u)
$$
关于反事实的一致性法则是，如果我们**观测到** $X = x$，那么反事实的结果与原结果保持不变,
$Y_{x} = Y$。

比如我们观测到 $X(u)= 1，Y(w)=0$  ,然后我们求反事实$Y_{x}=1(u)$ , 则 $Y_{x=1}(u)$也等于0。

因为其实没有“反”事实，$X = 1$ 就是事实。所以 $Y$ 也不会变。（是观察，而没有干预等方法，因此是“事实”）

##### 确定性模型的反事实

根据以上的例子，可以总结出计算反事实的方法:

1.**外展(Abduction)** : 使用证据 $E= e$ 来确定 $U$ 的值。(通过大数据统计等)

2.**干预(Action)** : 通过用 $X= x$ 来替换原来模型 $M$ 中变量 $X$ 的表达式,从而修改原模型 $M$ 为 $M_x$ 。加入干预可能需要断边。

3.**预测(Prediction)** :使用修改后的模型 $M_x$ 和第一步计算出的 $U$ 值来计算 $Y$ 值。

一个具体的例子参考博客：https://zhuanlan.zhihu.com/p/120909701

##### 非确定性模型的反事实

1.**外展(Abduction)** : 使用证据 $E= e$ 来确定 $P(U)$ 的值, 得到$P(U|E=e)$ 。(通过大数据统计等)

2.**干预(Action)** : 通过用 $X= x$ 来替换原来模型 $M$ 中变量 $X$ 的表达式,从而修改原模型 $M$ 为 $M_x$ 。加入干预可能需要断边。

3.**预测(Prediction)** :使用修改后的模型 $M_x$ 和第一步计算出的 $P(U|E=e)$ 值来计算 $Y$ 值。

使用中介时不能把中介当做条件（否则会断开联系）。用之前的公式代入即可。

![1.15.png](https://github.com/H-shw/Transformer_etc./blob/master/notes/casual%20inference/pics/1.15.png?raw=true)

##### 估计$P(Y_{x}=y)$的一种方法

**定理**：如果变量集 $Z$ 满足 $X→Y$ 的后门条件, 那么对于所有可能的 $x$ ，反事实 $Y_x$ 都与 $X$ 以 $Z$ 为条件独立。
$$
P(Y_{x}|X,Z)= P(Y_{x}|Z)
$$
由此：
$$
\begin{align*}
&// 全概率公式 \\
P(Y_{x} =y) &= \sum_{z} P(Y_{x} = y|Z= z)P(Z= z)\\
&// 上述定理运用，加入 X\\
&= \sum_{z} P(Y_{x} =y|Z=z,X=x)P(Z= z)\\
&// 一致性原则，观察到X则 \,\, P(Y=y|X)=P(Y_x)\\
&= \sum_{z} P(Y=y|Z=z,X=x)P(Z= z)
\end{align*}
$$

##### 线性系统中估计的方法

定理：$X$ 对 $Y$ 的总效应的斜率 $\tau$ 如下:

$\tau = E[Y|do(x + 1)] - E[Y|do(x)]$



那么，对于任何 $E$ 知的证据 $Z = e$ 都有:

$E[Y_x = x|Z=e] = E[Y|Z=e]+ \tau(x- E[X|Z= e])$

(像线性方程一样理解即可 $y=ax+b$)

##### ETT(effect of treatment on the treated) 参与者处理效应

用来评估获得处理的人是否能从该处理中受益。

比如：如果参加了课外辅导的人没有参加课外辅导的话，他的考试成绩会有怎样的变化。($X$ 为参与培训，相当于我们在已知此人参加了辅导班($X=1$)的情况下，求参加辅导班($Y_1$)比不参加辅导班($Y_{0}$)的收益增加多少)
$$
ETT= E[Y_{1}-Y_{0}|X= 1]
$$
一个计算过程
$$
\begin{align*}
ETT &= E[Y_{1} - Y_{0}|X= 1]\\
&= E[Y_1|X = 1]- E[Y_{0}|X = 1]\\
&= E[Y|X= 1]- \sum_{z} E[Y|X =0,Z=z]P(Z=z|X = 1)
\end{align*}
$$
其中 第三步需要一个推导过程
$$
\begin{align*}
&因为P(Y_{x} =y) = \sum_{z} P(Y=y|Z=z,X=x)P(Z= z)\\
&因此P(Y_{x'} =y|X) = \sum_{z} P(Y_{x'}=y|Z=z,X=x)P(Z= z|X = x)\\
&因为在以Z为条件时，X与Y的关系被切断\\
&因此P(Y_{x'} =y|X) = \sum_{z} P(Y=y_{x'}|Z=z,X=x')P(Z= z|X = x)\\
&根据一致性原则，消去 x'\\
&P(Y_{x'} =y|X) = \sum_{z} P(Y=y|Z=z,X=x')P(Z= z|X = x)
\end{align*}
$$

##### 必要性概率 PN

$$
PN = P(Y_{0}=0|X=1,Y=1)
$$

可以理解为，在已经处理过($X=1$) 且取得了成效(如治疗成功，$Y=1$ )的情况下，推想直接没有接受处理($X=0$)且治疗失败($Y_{X}=0$)的概率。

##### 充分性概率 PS

$$
PS = P(Y_{1} = 1|X = 0, Y = 0)
$$

##### 充分必要概率 PNS

$PNS = P(Y_1 = 1, Y_0 = 0)$

$PNS = P(Y = 1|do(X = 1)) − P(Y = 1|do(X = 0))$



## 资源栏

因果博客 https://zhuanlan.zhihu.com/p/109729340

参考书籍：*CAUSAL INFERENCE IN STATISTICS A PRIMER* (https://zh.usa1lib.org/book/2664651/adcbf6) pdf版下载地址

do-calculus 的 3个公理:https://zhuanlan.zhihu.com/p/336128992

